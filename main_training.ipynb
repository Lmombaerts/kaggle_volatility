{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code for Kaggle - Optiver Realized Volatility Prediction\n",
    "@LaurentMombaerts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lib Import / Data loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Maths\n",
    "import nolds\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Paths tricks\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Support code\n",
    "from support_file import *\n",
    "\n",
    "datapath = os.path.join(str(Path.home()), 'ownCloud', 'Data', 'Kaggle', 'optiver-realized-volatility-prediction')\n",
    "\n",
    "# Load dataset\n",
    "train = pd.read_csv(os.path.join(datapath,'train.csv')) \n",
    "all_stocks_ids = train['stock_id'].unique()\n",
    "all_time_ids = train['time_id'].unique()\n",
    "\n",
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "train = train[['row_id','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "# Prediction function (chose here which prediction strategy to use)\n",
    "def prediction_function(pred,book_path_train,trade_path_train,targets,book_path_test,trade_path_test):\n",
    "    \n",
    "    if pred == 'naive':\n",
    "        # Naive prediction (persistence model)\n",
    "        prediction = past_realized_volatility_per_stock(list_file=book_path_train,prediction_column_name='pred')\n",
    "        \n",
    "        # Merge and evaluate results\n",
    "        prediction = train.merge(prediction[['row_id','pred']], on = ['row_id'], how = 'left')\n",
    "        print(prediction.head(5))\n",
    "\n",
    "        # Estimate performances\n",
    "        R2 = round(r2_score(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "        RMSPE = round(rmspe(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "\n",
    "        print('--')\n",
    "        print(f'Performance of prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n",
    "        \n",
    "        prediction = prediction.drop(columns=['target'])\n",
    "        prediction = prediction.rename(columns={'pred': 'target'})\n",
    "\n",
    "    if pred == 'stupid_RF':\n",
    "        # Stupid nonlinear regression between persistence and next volatility (random forest)\n",
    "        prediction = stupidForestPrediction(book_path_train=book_path_train,\n",
    "                                            prediction_column_name='pred',\n",
    "                                            train_targets_pd=targets,\n",
    "                                            book_path_test=book_path_test)\n",
    "        \n",
    "    if pred == 'entropy_based':\n",
    "        prediction = entropy_Prediction(book_path_train=book_path_train,\n",
    "                                            prediction_column_name='pred',\n",
    "                                            train_targets_pd=targets,\n",
    "                                            book_path_test=book_path_test)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a prediction code\n",
    "\n",
    "# Glob book file train (contains all paths for each file in this folder)\n",
    "list_order_book_file_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "list_order_book_file_test = glob.glob(os.path.join(datapath,'book_test.parquet','*'))\n",
    "list_trade_file_train = glob.glob(os.path.join(datapath,'trade_train.parquet','*')) \n",
    "list_trade_file_test = glob.glob(os.path.join(datapath,'trade_test.parquet','*'))\n",
    "\n",
    "# Given variables\n",
    "pred = 'entropy_based'\n",
    "book_path_train = list_order_book_file_train\n",
    "trade_path_train = list_trade_file_train\n",
    "targets = train\n",
    "book_path_test = list_order_book_file_test\n",
    "trade_path_test = list_trade_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock id computing = 0...\n",
      "Computing one stock entropy took 161.8463773727417 seconds for stock  0\n"
     ]
    }
   ],
   "source": [
    "# Memory efficient version\n",
    "book_all_features = pd.DataFrame()\n",
    "encoder = np.eye(len(all_stocks_ids))\n",
    "\n",
    "#for file in book_path_train:\n",
    "\n",
    "file = book_path_train[0]\n",
    "start = time.time()\n",
    "\n",
    "book_stock = pd.read_parquet(file)\n",
    "stock_id = file.split('=')[1]\n",
    "print('stock id computing = ' + str(stock_id) + '...')\n",
    "\n",
    "# Compute outside of loops\n",
    "book_stock['wap'] = compute_wap(book_stock)\n",
    "book_stock['log_return'] = book_stock.groupby(['time_id'])['wap'].apply(log_return)\n",
    "book_stock = book_stock[~book_stock['log_return'].isnull()]\n",
    "\n",
    "# Compute the square root of the sum of log return squared to get realized volatility\n",
    "realized_vol = book_stock.groupby(['time_id'])['log_return'].agg(realized_volatility)\n",
    "df_realized_vol_per_stock =  pd.DataFrame(realized_vol).reset_index()\n",
    "\n",
    "entropy = book_stock.groupby(['time_id']).agg(entropy_from_book,last_min=10)\n",
    "entropy_5 = book_stock.groupby(['time_id']).agg(entropy_from_book,last_min=5)\n",
    "entropy_2 = book_stock.groupby(['time_id']).agg(entropy_from_book,last_min=2)\n",
    "\n",
    "print('Computing one stock entropy took', time.time() - start, 'seconds for stock ', stock_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock id computing = 0\n",
      "Computing one stock entropy took 24.178353309631348 seconds for stock  0\n",
      "stock id computing = 1\n",
      "Computing one stock entropy took 30.833398818969727 seconds for stock  1\n",
      "stock id computing = 10\n",
      "Computing one stock entropy took 37.619232416152954 seconds for stock  10\n",
      "stock id computing = 100\n",
      "Computing one stock entropy took 39.2470760345459 seconds for stock  100\n",
      "stock id computing = 101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d9860821cb0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Concatenate features, rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mbook_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbook_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoded_stock_pd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mbook_all_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbook_all_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbook_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Computing one stock entropy took'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seconds for stock '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstock_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 503\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             )\n\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "book_all_features = pd.DataFrame()\n",
    "encoder = np.eye(len(all_stocks_ids))\n",
    "\n",
    "for file in book_path_train:\n",
    "    start = time.time()\n",
    "\n",
    "    #file = book_path_train[0]\n",
    "    book_stock = pd.read_parquet(file)\n",
    "    stock_id = file.split('=')[1]\n",
    "    print('stock id computing = ' + str(stock_id))\n",
    "    for time_id in all_time_ids:     \n",
    "\n",
    "        # Access book data at this time + stock\n",
    "        book_stock_time = book_stock[book_stock['time_id'] == time_id]\n",
    "\n",
    "        # Create feature matrix\n",
    "        book_features = pd.DataFrame()\n",
    "        book_features['stock_id'] = [stock_id]\n",
    "        book_features['time_id'] = [time_id]\n",
    "        book_features['row_id'] = book_features['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
    "\n",
    "        # Hand-designed features\n",
    "        book_features['volatility'] = realized_volatility_from_book_pd(book_stock_time=book_stock_time)\n",
    "        #book_features['entropy'] = entropy_from_book(book_stock_time=book_stock_time,last_min=10)  \n",
    "        #book_features['entropy_last5'] = entropy_from_book(book_stock_time=book_stock_time,last_min=5)\n",
    "        #book_features['entropy_last2'] = entropy_from_book(book_stock_time=book_stock_time,last_min=2)\n",
    "\n",
    "        encoded_stock = encoder[np.where(all_stocks_ids == int(stock_id))[0],:]   \n",
    "        encoded_stock_pd = pd.DataFrame(encoded_stock)\n",
    "\n",
    "        # Concatenate features, rows\n",
    "        book_features = pd.concat([book_features,encoded_stock_pd],axis=1)   \n",
    "        book_all_features = pd.concat([book_all_features,book_features])\n",
    "    \n",
    "    print('Computing one stock entropy took', time.time() - start, 'seconds for stock ', stock_id)\n",
    "\n",
    "# Merge targets\n",
    "#book_all_features = book_all_features.merge(train, on = ['row_id'])\n",
    "book_all_features = train.merge(book_all_features, on = ['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>volatility</th>\n",
       "      <th>entropy</th>\n",
       "      <th>entropy_last5</th>\n",
       "      <th>entropy_last2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.368289</td>\n",
       "      <td>0.404234</td>\n",
       "      <td>0.357092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.153010</td>\n",
       "      <td>0.202383</td>\n",
       "      <td>0.173592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.065993</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>0.069548</td>\n",
       "      <td>0.076961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.191776</td>\n",
       "      <td>0.241762</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0-32751</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.140980</td>\n",
       "      <td>0.165372</td>\n",
       "      <td>0.273807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0-32753</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.098837</td>\n",
       "      <td>0.086843</td>\n",
       "      <td>0.059258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0-32758</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.147842</td>\n",
       "      <td>0.301443</td>\n",
       "      <td>0.658361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0-32763</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.606075</td>\n",
       "      <td>0.259420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0-32767</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.121523</td>\n",
       "      <td>0.315758</td>\n",
       "      <td>0.307783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id    target stock_id  time_id  volatility   entropy  \\\n",
       "0         0-5  0.004136        0        5    0.004499  0.368289   \n",
       "1        0-11  0.001445        0       11    0.001204  0.153010   \n",
       "2        0-16  0.002168        0       16    0.002369  0.105023   \n",
       "3        0-31  0.002195        0       31    0.002574  0.069853   \n",
       "4        0-62  0.001747        0       62    0.001894  0.191776   \n",
       "...       ...       ...      ...      ...         ...       ...   \n",
       "3825  0-32751  0.002611        0    32751    0.002579  0.140980   \n",
       "3826  0-32753  0.001190        0    32753    0.002206  0.098837   \n",
       "3827  0-32758  0.004264        0    32758    0.002913  0.147842   \n",
       "3828  0-32763  0.004352        0    32763    0.003046  0.471413   \n",
       "3829  0-32767  0.001084        0    32767    0.001901  0.121523   \n",
       "\n",
       "      entropy_last5  entropy_last2    0    1  ...  102  103  104  105  106  \\\n",
       "0          0.404234       0.357092  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "1          0.202383       0.173592  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "2          0.065993       0.066508  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3          0.069548       0.076961  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "4          0.241762       0.164630  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "...             ...            ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3825       0.165372       0.273807  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3826       0.086843       0.059258  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3827       0.301443       0.658361  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3828       0.606075       0.259420  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "3829       0.315758       0.307783  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      107  108  109  110  111  \n",
       "0     0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "3825  0.0  0.0  0.0  0.0  0.0  \n",
       "3826  0.0  0.0  0.0  0.0  0.0  \n",
       "3827  0.0  0.0  0.0  0.0  0.0  \n",
       "3828  0.0  0.0  0.0  0.0  0.0  \n",
       "3829  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3830 rows x 120 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Persistence model perf : 0.39322701284497674\n",
      "New model perf :  0.32213065513839995\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X = book_all_features.drop(['row_id','target','stock_id','time_id'],axis=1)\n",
    "y = book_all_features['target']\n",
    "\n",
    "x_test = X # to change\n",
    "\n",
    "xgboost_default = xgb.XGBRegressor(random_state=0)\n",
    "xgboost_default.fit(X,y)\n",
    "\n",
    "yhat = xgboost_default.predict(x_test)\n",
    "print('Persistence model perf :', rmspe(y,book_all_features['volatility']))\n",
    "print('New model perf : ', rmspe(y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main evaluation code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob book file train (contains all paths for each file in this folder)\n",
    "list_order_book_file_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "list_order_book_file_test = glob.glob(os.path.join(datapath,'book_test.parquet','*'))\n",
    "list_trade_file_train = glob.glob(os.path.join(datapath,'trade_train.parquet','*')) \n",
    "list_trade_file_test = glob.glob(os.path.join(datapath,'trade_test.parquet','*'))\n",
    "\n",
    "# Compute predictions\n",
    "prediction = prediction_function(pred='stupid_RF',\n",
    "                                 book_path_train=list_order_book_file_train,\n",
    "                                 trade_path_train=list_trade_file_train,\n",
    "                                 targets=train,\n",
    "                                 book_path_test=list_order_book_file_test,\n",
    "                                 trade_path_test=list_trade_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
