{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Main code for Kaggle - Optiver Realized Volatility Prediction\n",
    "@LaurentMombaerts "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%reset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MACHINE TO SET UP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "###########################\n",
    "machine = 'local'\n",
    "###########################"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Lib Import / Data loading**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Parallel Computing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Maths\n",
    "from scipy.interpolate import interp1d\n",
    "# from arch import arch_model\n",
    "\n",
    "# Paths tricks\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Support code\n",
    "from support_file import *\n",
    "from information_measures import *\n",
    "\n",
    "if machine == 'local':\n",
    "    datapath = os.path.join(str(Path.home()), 'ownCloud', 'Data', 'Kaggle', 'optiver-realized-volatility-prediction')\n",
    "\n",
    "    # Load dataset\n",
    "    train = pd.read_csv(os.path.join(datapath,'train.csv')) \n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    # Load test ids\n",
    "    test = pd.read_csv(os.path.join(datapath,'test.csv'))\n",
    "    all_stocks_ids_test = test['stock_id'].unique()\n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "elif machine == 'kaggle':\n",
    "    \n",
    "    # Load dataset\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv') \n",
    "    all_stocks_ids_test = test['stock_id'].unique()\n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "    datapath = 0\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Functions**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def trainModel_timeSplit(X,y,groups,model,splits):\n",
    "    \n",
    "    rmspe_list = []\n",
    "    \n",
    "    for random_split in range(splits):\n",
    "        gss = GroupShuffleSplit(n_splits=1, train_size=.80, random_state=random_split)\n",
    "        gss.get_n_splits()\n",
    "\n",
    "        for train, test in gss.split(X, y, groups):\n",
    "            # CV definition\n",
    "            X_train, X_test = X.iloc[train,:], X.iloc[test,:]\n",
    "            y_train, y_test = y[train],y[test]\n",
    "            \n",
    "            # Add other stocks volatility at same time id and this stock overall volatility\n",
    "            X_test = get_time_stock(X_test).drop(['time_id','stock_id'],axis=1)\n",
    "            X_train = get_time_stock(X_train).drop(['time_id','stock_id'],axis=1)\n",
    "    \n",
    "            # Model definition\n",
    "            model.fit(X_train,y_train)\n",
    "            yhat = model.predict(X_test)\n",
    "    \n",
    "            # Estimate perf\n",
    "            rmspe_list.append(rmspe(y_test, yhat))\n",
    "            \n",
    "    return rmspe_list\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    \n",
    "    # df['stock_id'] = [df['row_id'][i].split('-')[0] for i in range(df.shape[0])]\n",
    "    # df['time_id'] = [df['row_id'][i].split('-')[1] for i in range(df.shape[0])]\n",
    "            \n",
    "    # Get realized volatility columns\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_returnMidprice_realized_volatility']\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the time id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_CatBoost_cv(df_features_train,targets,splits):\n",
    "    \n",
    "    model = CatBoostRegressor(verbose=0)\n",
    "\n",
    "    # Data input / output definition\n",
    "    X = df_features_train.fillna(0)\n",
    "    y = targets\n",
    "    time_id_groups = [df_features_train['row_id'][i].split('-')[1] for i in range(df_features_train.shape[0])]\n",
    "   \n",
    "    rmspe_list = trainModel_timeSplit(X,y,time_id_groups,model,splits)\n",
    "    \n",
    "    return rmspe_list\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    \n",
    "    y_true = lgb_train.get_label()\n",
    "    \n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_lgbm_cv(df_features_train,targets,splits):\n",
    "    \n",
    "    # Data input / output definition\n",
    "    X = df_features_train.fillna(0)\n",
    "    y = targets\n",
    "    time_id_groups = [df_features_train['time_id'][i] for i in range(df_features_train.shape[0])]\n",
    "\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'num_leaves': 100,\n",
    "      'n_jobs': -1,\n",
    "      'learning_rate': 0.1,\n",
    "      'feature_fraction': 0.8,\n",
    "      'bagging_fraction': 0.8,\n",
    "      'verbose': -1\n",
    "    }\n",
    "\n",
    "    rmspe_list = []\n",
    "\n",
    "    for random_split in range(splits):\n",
    "        gss = GroupShuffleSplit(n_splits=1, train_size=.80, random_state=random_split)\n",
    "        gss.get_n_splits()\n",
    "\n",
    "        for train, test in gss.split(X, y, time_id_groups):\n",
    "            # CV definition\n",
    "            x_train, x_val = X.iloc[train,:].reset_index(drop=True), X.iloc[test,:].reset_index(drop=True)\n",
    "            y_train, y_val = y[train].reset_index(drop=True),y[test].reset_index(drop=True)\n",
    "\n",
    "            # Add other stocks volatility at same time id and this stock overall volatility\n",
    "            x_val = get_time_stock(x_val).drop(['time_id'],axis=1)\n",
    "            x_val['stock_id'] = x_val['stock_id'].astype(int)\n",
    "            x_train = get_time_stock(x_train).drop(['time_id'],axis=1)\n",
    "            x_train['stock_id'] = x_train['stock_id'].astype(int)\n",
    "\n",
    "            # Root mean squared percentage error weights\n",
    "            train_weights = 1 / np.square(y_train)\n",
    "            val_weights = 1 / np.square(y_val)\n",
    "            train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "            val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights, categorical_feature = ['stock_id'])\n",
    "\n",
    "            # Model definition\n",
    "            model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 10000, \n",
    "                          early_stopping_rounds = 50, \n",
    "                          verbose_eval = 50,\n",
    "                          feval = feval_rmspe)\n",
    "\n",
    "            yhat = model.predict(x_val) \n",
    "\n",
    "            # Estimate perf\n",
    "            rmspe_list.append(rmspe(y_val, yhat))\n",
    "            \n",
    "    return rmspe_list\n",
    "\n",
    "def train_lgbm(df_features_train,targets):\n",
    "    \n",
    "    # Data input / output definition\n",
    "    X = df_features_train.fillna(0)\n",
    "    X['stock_id'] = X['stock_id'].astype(int)\n",
    "    y = targets\n",
    "\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'num_leaves': 100,\n",
    "      'n_jobs': -1,\n",
    "      'learning_rate': 0.1,\n",
    "      'feature_fraction': 0.8,\n",
    "      'bagging_fraction': 0.8,\n",
    "      'verbose': -1\n",
    "    }\n",
    "\n",
    "    X['stock_id'] = X['stock_id'].astype(int)\n",
    "            \n",
    "    # Root mean squared percentage error weights\n",
    "    train_weights = 1 / np.square(y)\n",
    "    train_dataset = lgb.Dataset(X, y, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "\n",
    "    # Model definition\n",
    "    model = lgb.train(params = params, \n",
    "                  train_set = train_dataset, \n",
    "                  num_boost_round = 50, \n",
    "                  verbose_eval = 50,\n",
    "                  feval = feval_rmspe)\n",
    "            \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Competition metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "# Prediction function (chose here which prediction strategy to use)\n",
    "def prediction_function(pred, machine, targets, all_stocks_ids, datapath, test, all_stocks_ids_test):\n",
    "        \n",
    "    if pred == 'entropy':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_train['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent_withoutEncoding':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent_withoutEncoding_wTrades':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "        \n",
    "    if pred == 'garch':\n",
    "        \n",
    "        if machine == 'local':\n",
    "            book_path_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "            \n",
    "            # fit garch and predict\n",
    "            prediction = garch_volatility_per_stock(list_file=book_path_train, prediction_column_name='pred')\n",
    "            \n",
    "            # Merge and evaluate results\n",
    "            prediction = train.merge(prediction[['row_id','pred']], on = ['row_id'], how = 'left')\n",
    "            prediction = prediction[prediction.pred.notnull()]\n",
    "\n",
    "            # Estimate performances\n",
    "            R2 = round(r2_score(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "            RMSPE = round(rmspe(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "\n",
    "            print('--')\n",
    "            print(f'Performance of prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n",
    "\n",
    "            prediction = prediction.drop(columns=['target'])\n",
    "            prediction = prediction.rename(columns={'pred': 'target'})\n",
    "            \n",
    "            return prediction\n",
    "        \n",
    "\n",
    "    if pred == 'test_2807':\n",
    "        if machine == 'local':\n",
    "\n",
    "            # Load data\n",
    "            df_features_test = computeFeatures_2807(machine=machine, dataset='test', all_stocks_ids=[0], datapath=datapath).fillna(0)\n",
    "            df_features_train = computeFeatures_2807(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath).fillna(0)\n",
    "\n",
    "            # saving features to the .csv file\n",
    "            print('['+time.strftime('%X')+']', 'Saving features to .csv files ...') # print also time\n",
    "            df_features_train.to_csv('df_features_train.csv')\n",
    "            df_features_test.to_csv('df_features_test.csv')\n",
    "                              \n",
    "            # Modelling\n",
    "            start = time.time()\n",
    "            print('['+time.strftime('%X')+']', 'Model Training on splits...')\n",
    "            \n",
    "            # Model list\n",
    "            #list_rmspe = train_CatBoost_cv(df_features_train=df_features_train,targets=targets,splits=10)\n",
    "            list_rmspe = train_lgbm_cv(df_features_train=df_features_train,targets=targets,splits=10)\n",
    "            \n",
    "            print('['+time.strftime('%X')+']', 'Training on splits took ',  time.time() - start, 'seconds')\n",
    "            \n",
    "            # Print results\n",
    "            print(list_rmspe)\n",
    "            print('Mean of RMSPE : ', np.mean(np.array(list_rmspe)), ' +- ', np.std(np.array(list_rmspe)))\n",
    "            \n",
    "            return df_features_train # Returns the feature in local mode for further use\n",
    "\n",
    "        # Features computation\n",
    "        df_features_test = computeFeatures_2807(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids_test, datapath=datapath).fillna(0)\n",
    "        df_features_test = test.merge(df_features_test, on = ['row_id'], how = 'left') # Should ensure order of predictions\n",
    "        df_features_train = computeFeatures_2807(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath).fillna(0)\n",
    "        rows_id_to_merge = df_features_test['row_id'].copy()\n",
    "        \n",
    "        # Add other stocks volatility at same time id and this stock overall volatility\n",
    "        df_features_test = get_time_stock(df_features_test).drop(['row_id','time_id'],axis=1)\n",
    "        df_features_test['stock_id'] = df_features_test['stock_id'].astype(int)\n",
    "        df_features_train = get_time_stock(df_features_train).drop(['row_id','time_id'],axis=1)\n",
    "        \n",
    "        # Optimized model\n",
    "        model = train_lgbm(df_features_train=df_features_train, targets=targets)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        yhat = model.predict(df_features_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([rows_id_to_merge,yhat_pd],axis=1)    \n",
    "\n",
    "    return submission_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Submission**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# New sub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_submission = prediction_function(pred='test_2807',machine=machine,targets=train['target'],all_stocks_ids=all_stocks_ids, datapath=datapath, test=test, all_stocks_ids_test=all_stocks_ids_test)\n",
    "# if machine == 'kaggle':\n",
    "#     df_submission.to_csv('submission.csv',index=False)\n",
    "# else:\n",
    "#     df_submission.iloc[0:10,:].to_csv('features_train_head.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "features_temp = pd.read_csv('df_features_train.csv')\n",
    "del features_temp['Unnamed: 0']\n",
    "features_temp['stock_id'] = features_temp['row_id'].apply(lambda x: int(x.split('-')[0]))\n",
    "features_temp['time_id']  = features_temp['row_id'].apply(lambda x: int(x.split('-')[1]))\n",
    "del features_temp['row_id']\n",
    "features_temp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           wap_sum  wap_mean   wap_std  mid_price_sum  mid_price_mean  \\\n",
       "0       303.125061  1.003725  0.000693     303.129970        1.003742   \n",
       "1       200.047768  1.000239  0.000262     200.041690        1.000209   \n",
       "2       187.913849  0.999542  0.000864     187.918460        0.999566   \n",
       "3       119.859781  0.998832  0.000757     119.864975        0.998875   \n",
       "4       175.932865  0.999619  0.000258     175.930570        0.999606   \n",
       "...            ...       ...       ...            ...             ...   \n",
       "428927  309.870466  0.999582  0.000486     309.824550        0.999434   \n",
       "428928  223.552143  1.002476  0.001264     223.528810        1.002371   \n",
       "428929  256.277050  1.001082  0.000466     256.211550        1.000826   \n",
       "428930  399.721736  1.001809  0.000456     399.748570        1.001876   \n",
       "428931  217.058919  1.000272  0.000384     217.063980        1.000295   \n",
       "\n",
       "        mid_price_std  log_return1_sum  log_return1_realized_volatility  \\\n",
       "0            0.000589         0.002292                         0.004499   \n",
       "1            0.000241         0.000360                         0.001204   \n",
       "2            0.000746        -0.002074                         0.002369   \n",
       "3            0.000616        -0.002828                         0.002574   \n",
       "4            0.000194        -0.000002                         0.001894   \n",
       "...               ...              ...                              ...   \n",
       "428927       0.000465        -0.000527                         0.003691   \n",
       "428928       0.001278         0.004436                         0.004104   \n",
       "428929       0.000455         0.001525                         0.003118   \n",
       "428930       0.000410         0.000256                         0.003661   \n",
       "428931       0.000346        -0.000727                         0.002091   \n",
       "\n",
       "        log_return1_mean  log_return1_std  ...  trade_size_sum  \\\n",
       "0           7.613599e-06         0.000260  ...          3179.0   \n",
       "1           1.810239e-06         0.000086  ...          1289.0   \n",
       "2          -1.109201e-05         0.000173  ...          2161.0   \n",
       "3          -2.376661e-05         0.000236  ...          1962.0   \n",
       "4          -1.057099e-08         0.000144  ...          1791.0   \n",
       "...                  ...              ...  ...             ...   \n",
       "428927     -1.706835e-06         0.000210  ...          2570.0   \n",
       "428928      1.998029e-05         0.000275  ...          2323.0   \n",
       "428929      5.979199e-06         0.000196  ...          3740.0   \n",
       "428930      6.429922e-07         0.000184  ...          9389.0   \n",
       "428931     -3.363982e-06         0.000143  ...          5325.0   \n",
       "\n",
       "        trade_order_count_sum  trade_order_count_mean  trade_roll_measure  \\\n",
       "0                       110.0                2.750000            0.000204   \n",
       "1                        57.0                1.900000            0.000463   \n",
       "2                        68.0                2.720000            0.000407   \n",
       "3                        59.0                3.933333            0.000738   \n",
       "4                        89.0                4.045455            0.000362   \n",
       "...                       ...                     ...                 ...   \n",
       "428927                  103.0                2.783784            0.000244   \n",
       "428928                  147.0                3.418605            0.000497   \n",
       "428929                   98.0                2.800000            0.000776   \n",
       "428930                  234.0                2.925000            0.000184   \n",
       "428931                  108.0                3.000000            0.000091   \n",
       "\n",
       "        trade_roll_impact  trade_amihud  trade_traded_volume  \\\n",
       "0            6.382619e-08  4.216972e-07          3190.139181   \n",
       "1            3.589880e-07  6.228642e-07          1289.353432   \n",
       "2            1.886683e-07  1.175238e-06          2158.608928   \n",
       "3            3.764258e-07  1.152450e-06          1959.605547   \n",
       "4            2.023833e-07  1.531390e-07          1790.254496   \n",
       "...                   ...           ...                  ...   \n",
       "428927       9.479032e-08  4.704802e-07          2568.838117   \n",
       "428928       2.134959e-07  2.091255e-06          2327.828627   \n",
       "428929       2.072699e-07  3.455508e-07          3742.254714   \n",
       "428930       1.950722e-08  2.399810e-08          9406.795437   \n",
       "428931       1.705715e-08  1.918151e-07          5326.415054   \n",
       "\n",
       "        trade_avg_trade_size  stock_id  time_id  \n",
       "0                  28.900000         0        5  \n",
       "1                  22.614035         0       11  \n",
       "2                  31.779412         0       16  \n",
       "3                  33.254237         0       31  \n",
       "4                  20.123596         0       62  \n",
       "...                      ...       ...      ...  \n",
       "428927             24.951456       126    32751  \n",
       "428928             15.802721       126    32753  \n",
       "428929             38.163265       126    32758  \n",
       "428930             40.123932       126    32763  \n",
       "428931             49.305556       126    32767  \n",
       "\n",
       "[428932 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wap_sum</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>wap_std</th>\n",
       "      <th>mid_price_sum</th>\n",
       "      <th>mid_price_mean</th>\n",
       "      <th>mid_price_std</th>\n",
       "      <th>log_return1_sum</th>\n",
       "      <th>log_return1_realized_volatility</th>\n",
       "      <th>log_return1_mean</th>\n",
       "      <th>log_return1_std</th>\n",
       "      <th>...</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_roll_measure</th>\n",
       "      <th>trade_roll_impact</th>\n",
       "      <th>trade_amihud</th>\n",
       "      <th>trade_traded_volume</th>\n",
       "      <th>trade_avg_trade_size</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303.125061</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>303.129970</td>\n",
       "      <td>1.003742</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>7.613599e-06</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>...</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>6.382619e-08</td>\n",
       "      <td>4.216972e-07</td>\n",
       "      <td>3190.139181</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.047768</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>200.041690</td>\n",
       "      <td>1.000209</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>1.810239e-06</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>...</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>3.589880e-07</td>\n",
       "      <td>6.228642e-07</td>\n",
       "      <td>1289.353432</td>\n",
       "      <td>22.614035</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187.913849</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>187.918460</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-1.109201e-05</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>...</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>1.886683e-07</td>\n",
       "      <td>1.175238e-06</td>\n",
       "      <td>2158.608928</td>\n",
       "      <td>31.779412</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.859781</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>119.864975</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-2.376661e-05</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>...</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>3.764258e-07</td>\n",
       "      <td>1.152450e-06</td>\n",
       "      <td>1959.605547</td>\n",
       "      <td>33.254237</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.932865</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>175.930570</td>\n",
       "      <td>0.999606</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-1.057099e-08</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>...</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>2.023833e-07</td>\n",
       "      <td>1.531390e-07</td>\n",
       "      <td>1790.254496</td>\n",
       "      <td>20.123596</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>309.870466</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>309.824550</td>\n",
       "      <td>0.999434</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>-1.706835e-06</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>...</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.783784</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>9.479032e-08</td>\n",
       "      <td>4.704802e-07</td>\n",
       "      <td>2568.838117</td>\n",
       "      <td>24.951456</td>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>223.552143</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>223.528810</td>\n",
       "      <td>1.002371</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>1.998029e-05</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>...</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>3.418605</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>2.134959e-07</td>\n",
       "      <td>2.091255e-06</td>\n",
       "      <td>2327.828627</td>\n",
       "      <td>15.802721</td>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>256.277050</td>\n",
       "      <td>1.001082</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>256.211550</td>\n",
       "      <td>1.000826</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>5.979199e-06</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>...</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>2.072699e-07</td>\n",
       "      <td>3.455508e-07</td>\n",
       "      <td>3742.254714</td>\n",
       "      <td>38.163265</td>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>399.721736</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>399.748570</td>\n",
       "      <td>1.001876</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>6.429922e-07</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>...</td>\n",
       "      <td>9389.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1.950722e-08</td>\n",
       "      <td>2.399810e-08</td>\n",
       "      <td>9406.795437</td>\n",
       "      <td>40.123932</td>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>217.058919</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>217.063980</td>\n",
       "      <td>1.000295</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>-3.363982e-06</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>...</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>1.705715e-08</td>\n",
       "      <td>1.918151e-07</td>\n",
       "      <td>5326.415054</td>\n",
       "      <td>49.305556</td>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 37 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add clusters to the `features_temp`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# read files\n",
    "stock_clusters = pd.read_csv('stock_clusters.csv')\n",
    "time_clusters = pd.read_csv('time_clusters.csv')\n",
    "\n",
    "# merge the tables into features_temp\n",
    "features_temp = pd.merge(features_temp, stock_clusters, on='stock_id', how='left')\n",
    "features_temp = pd.merge(features_temp, time_clusters, on='time_id', how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# normalize the data (only for appropriate columns)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = features_temp.loc[:, features_temp.columns[:-8]]\n",
    "scaler = preprocessing.StandardScaler().fit(data)\n",
    "data_scaled = scaler.transform(data)\n",
    "features_scaled = pd.concat([pd.DataFrame(data_scaled, columns=data.columns), features_temp.loc[:,features_temp.columns[-8:]]], axis=1)\n",
    "features_scaled"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         wap_sum  wap_mean   wap_std  mid_price_sum  mid_price_mean  \\\n",
       "0      -0.639031  1.104316 -0.396660      -0.639001        1.111899   \n",
       "1      -1.397873  0.069885 -0.806592      -1.397924        0.060385   \n",
       "2      -1.487201 -0.136938 -0.233761      -1.487174       -0.130757   \n",
       "3      -1.988207 -0.347661 -0.336160      -1.988175       -0.336548   \n",
       "4      -1.575404 -0.114151 -0.810551      -1.575427       -0.119067   \n",
       "...          ...       ...       ...            ...             ...   \n",
       "428927 -0.589373 -0.124951 -0.593530      -0.589716       -0.170105   \n",
       "428928 -1.224837  0.733630  0.146578      -1.225015        0.704073   \n",
       "428929 -0.983920  0.320113 -0.613047      -0.984409        0.244283   \n",
       "428930  0.072101  0.535701 -0.621808       0.072293        0.556692   \n",
       "428931 -1.272639  0.079579 -0.690180      -1.272608        0.086069   \n",
       "\n",
       "        mid_price_std  log_return1_sum  log_return1_realized_volatility  \\\n",
       "0           -0.469451         0.619973                         0.074238   \n",
       "1           -0.803573         0.100188                        -0.844596   \n",
       "2           -0.319051        -0.554959                        -0.519973   \n",
       "3           -0.444075        -0.757878                        -0.462721   \n",
       "4           -0.848177         0.002744                        -0.652162   \n",
       "...               ...              ...                              ...   \n",
       "428927      -0.588372        -0.138693                        -0.151275   \n",
       "428928       0.191491         1.196938                        -0.036057   \n",
       "428929      -0.598003         0.413562                        -0.311090   \n",
       "428930      -0.640814         0.072112                        -0.159511   \n",
       "428931      -0.703082        -0.192303                        -0.597245   \n",
       "\n",
       "        log_return1_mean  log_return1_std  ...  trade_traded_volume  \\\n",
       "0               0.705678         0.150592  ...            -0.408029   \n",
       "1               0.169450        -0.693876  ...            -0.435082   \n",
       "2              -1.022713        -0.268272  ...            -0.422710   \n",
       "3              -2.193842         0.034539  ...            -0.425542   \n",
       "4               0.001207        -0.412300  ...            -0.427953   \n",
       "...                  ...              ...  ...                  ...   \n",
       "428927         -0.155527        -0.088900  ...            -0.416872   \n",
       "428928          1.848355         0.226598  ...            -0.420302   \n",
       "428929          0.554660        -0.160531  ...            -0.400171   \n",
       "428930          0.061596        -0.217657  ...            -0.319551   \n",
       "428931         -0.308646        -0.417282  ...            -0.377625   \n",
       "\n",
       "        trade_avg_trade_size  stock_id  time_id  km_x  hc_x  ha_x  km_y  hc_y  \\\n",
       "0                  -0.469105         0        5     2     1     1     3     1   \n",
       "1                  -0.542342         0       11     2     1     1     1     1   \n",
       "2                  -0.435558         0       16     2     1     1     1     1   \n",
       "3                  -0.418375         0       31     2     1     1     1     1   \n",
       "4                  -0.571358         0       62     2     1     1     1     1   \n",
       "...                      ...       ...      ...   ...   ...   ...   ...   ...   \n",
       "428927             -0.515109       126    32751     2     1     1     1     1   \n",
       "428928             -0.621700       126    32753     2     1     1     1     1   \n",
       "428929             -0.361180       126    32758     2     1     1     1     1   \n",
       "428930             -0.338337       126    32763     2     1     1     1     1   \n",
       "428931             -0.231363       126    32767     2     1     1     1     1   \n",
       "\n",
       "        ha_y  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "428927     1  \n",
       "428928     1  \n",
       "428929     1  \n",
       "428930     1  \n",
       "428931     1  \n",
       "\n",
       "[428932 rows x 43 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wap_sum</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>wap_std</th>\n",
       "      <th>mid_price_sum</th>\n",
       "      <th>mid_price_mean</th>\n",
       "      <th>mid_price_std</th>\n",
       "      <th>log_return1_sum</th>\n",
       "      <th>log_return1_realized_volatility</th>\n",
       "      <th>log_return1_mean</th>\n",
       "      <th>log_return1_std</th>\n",
       "      <th>...</th>\n",
       "      <th>trade_traded_volume</th>\n",
       "      <th>trade_avg_trade_size</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>km_x</th>\n",
       "      <th>hc_x</th>\n",
       "      <th>ha_x</th>\n",
       "      <th>km_y</th>\n",
       "      <th>hc_y</th>\n",
       "      <th>ha_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.639031</td>\n",
       "      <td>1.104316</td>\n",
       "      <td>-0.396660</td>\n",
       "      <td>-0.639001</td>\n",
       "      <td>1.111899</td>\n",
       "      <td>-0.469451</td>\n",
       "      <td>0.619973</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.705678</td>\n",
       "      <td>0.150592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408029</td>\n",
       "      <td>-0.469105</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.397873</td>\n",
       "      <td>0.069885</td>\n",
       "      <td>-0.806592</td>\n",
       "      <td>-1.397924</td>\n",
       "      <td>0.060385</td>\n",
       "      <td>-0.803573</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>-0.844596</td>\n",
       "      <td>0.169450</td>\n",
       "      <td>-0.693876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435082</td>\n",
       "      <td>-0.542342</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.487201</td>\n",
       "      <td>-0.136938</td>\n",
       "      <td>-0.233761</td>\n",
       "      <td>-1.487174</td>\n",
       "      <td>-0.130757</td>\n",
       "      <td>-0.319051</td>\n",
       "      <td>-0.554959</td>\n",
       "      <td>-0.519973</td>\n",
       "      <td>-1.022713</td>\n",
       "      <td>-0.268272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422710</td>\n",
       "      <td>-0.435558</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.988207</td>\n",
       "      <td>-0.347661</td>\n",
       "      <td>-0.336160</td>\n",
       "      <td>-1.988175</td>\n",
       "      <td>-0.336548</td>\n",
       "      <td>-0.444075</td>\n",
       "      <td>-0.757878</td>\n",
       "      <td>-0.462721</td>\n",
       "      <td>-2.193842</td>\n",
       "      <td>0.034539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425542</td>\n",
       "      <td>-0.418375</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.575404</td>\n",
       "      <td>-0.114151</td>\n",
       "      <td>-0.810551</td>\n",
       "      <td>-1.575427</td>\n",
       "      <td>-0.119067</td>\n",
       "      <td>-0.848177</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>-0.652162</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>-0.412300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427953</td>\n",
       "      <td>-0.571358</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>-0.589373</td>\n",
       "      <td>-0.124951</td>\n",
       "      <td>-0.593530</td>\n",
       "      <td>-0.589716</td>\n",
       "      <td>-0.170105</td>\n",
       "      <td>-0.588372</td>\n",
       "      <td>-0.138693</td>\n",
       "      <td>-0.151275</td>\n",
       "      <td>-0.155527</td>\n",
       "      <td>-0.088900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416872</td>\n",
       "      <td>-0.515109</td>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>-1.224837</td>\n",
       "      <td>0.733630</td>\n",
       "      <td>0.146578</td>\n",
       "      <td>-1.225015</td>\n",
       "      <td>0.704073</td>\n",
       "      <td>0.191491</td>\n",
       "      <td>1.196938</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>1.848355</td>\n",
       "      <td>0.226598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420302</td>\n",
       "      <td>-0.621700</td>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>-0.983920</td>\n",
       "      <td>0.320113</td>\n",
       "      <td>-0.613047</td>\n",
       "      <td>-0.984409</td>\n",
       "      <td>0.244283</td>\n",
       "      <td>-0.598003</td>\n",
       "      <td>0.413562</td>\n",
       "      <td>-0.311090</td>\n",
       "      <td>0.554660</td>\n",
       "      <td>-0.160531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400171</td>\n",
       "      <td>-0.361180</td>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>0.072101</td>\n",
       "      <td>0.535701</td>\n",
       "      <td>-0.621808</td>\n",
       "      <td>0.072293</td>\n",
       "      <td>0.556692</td>\n",
       "      <td>-0.640814</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>-0.159511</td>\n",
       "      <td>0.061596</td>\n",
       "      <td>-0.217657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.338337</td>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>-1.272639</td>\n",
       "      <td>0.079579</td>\n",
       "      <td>-0.690180</td>\n",
       "      <td>-1.272608</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>-0.703082</td>\n",
       "      <td>-0.192303</td>\n",
       "      <td>-0.597245</td>\n",
       "      <td>-0.308646</td>\n",
       "      <td>-0.417282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377625</td>\n",
       "      <td>-0.231363</td>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 43 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train the model with these features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "my_list_rmspe = train_lgbm_cv(df_features_train=features_scaled,targets=train['target'],splits=10)\n",
    "my_list_rmspe1 = train_lgbm_cv(df_features_train=features_temp,targets=train['target'],splits=10)\n",
    "my_list_rmspe2 = train_lgbm_cv(df_features_train=features_temp.loc[:, features_temp.columns[:-6]],targets=train['target'],splits=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000454354\ttraining's RMSPE: 0.210554\tvalid_1's rmse: 0.000506848\tvalid_1's RMSPE: 0.233354\n",
      "[100]\ttraining's rmse: 0.000421573\ttraining's RMSPE: 0.195363\tvalid_1's rmse: 0.0005091\tvalid_1's RMSPE: 0.234391\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's rmse: 0.000440445\ttraining's RMSPE: 0.204108\tvalid_1's rmse: 0.000505266\tvalid_1's RMSPE: 0.232626\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000452985\ttraining's RMSPE: 0.209564\tvalid_1's rmse: 0.000493733\tvalid_1's RMSPE: 0.228868\n",
      "[100]\ttraining's rmse: 0.000418779\ttraining's RMSPE: 0.193739\tvalid_1's rmse: 0.000497153\tvalid_1's RMSPE: 0.230453\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 0.000452363\ttraining's RMSPE: 0.209276\tvalid_1's rmse: 0.000493557\tvalid_1's RMSPE: 0.228786\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000454283\ttraining's RMSPE: 0.209954\tvalid_1's rmse: 0.000497688\tvalid_1's RMSPE: 0.231618\n",
      "[100]\ttraining's rmse: 0.000419085\ttraining's RMSPE: 0.193687\tvalid_1's rmse: 0.000503294\tvalid_1's RMSPE: 0.234228\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 0.000450512\ttraining's RMSPE: 0.208212\tvalid_1's rmse: 0.000497301\tvalid_1's RMSPE: 0.231439\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000455758\ttraining's RMSPE: 0.209408\tvalid_1's rmse: 0.000484983\tvalid_1's RMSPE: 0.230822\n",
      "[100]\ttraining's rmse: 0.000423108\ttraining's RMSPE: 0.194406\tvalid_1's rmse: 0.000487984\tvalid_1's RMSPE: 0.23225\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's rmse: 0.000451184\ttraining's RMSPE: 0.207307\tvalid_1's rmse: 0.000484151\tvalid_1's RMSPE: 0.230426\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000453491\ttraining's RMSPE: 0.210648\tvalid_1's rmse: 0.000504916\tvalid_1's RMSPE: 0.230237\n",
      "[100]\ttraining's rmse: 0.000418886\ttraining's RMSPE: 0.194574\tvalid_1's rmse: 0.000507258\tvalid_1's RMSPE: 0.231305\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 0.000445904\ttraining's RMSPE: 0.207124\tvalid_1's rmse: 0.000503751\tvalid_1's RMSPE: 0.229706\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000447329\ttraining's RMSPE: 0.208822\tvalid_1's rmse: 0.0005252\tvalid_1's RMSPE: 0.234462\n",
      "[100]\ttraining's rmse: 0.000416148\ttraining's RMSPE: 0.194266\tvalid_1's rmse: 0.000527637\tvalid_1's RMSPE: 0.23555\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 0.00044605\ttraining's RMSPE: 0.208225\tvalid_1's rmse: 0.000524718\tvalid_1's RMSPE: 0.234247\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000454698\ttraining's RMSPE: 0.210448\tvalid_1's rmse: 0.000494016\tvalid_1's RMSPE: 0.2286\n",
      "[100]\ttraining's rmse: 0.00042102\ttraining's RMSPE: 0.194862\tvalid_1's rmse: 0.000497386\tvalid_1's RMSPE: 0.230159\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 0.000453642\ttraining's RMSPE: 0.20996\tvalid_1's rmse: 0.000493905\tvalid_1's RMSPE: 0.228549\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000453184\ttraining's RMSPE: 0.209978\tvalid_1's rmse: 0.000501883\tvalid_1's RMSPE: 0.231216\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's rmse: 0.000454632\ttraining's RMSPE: 0.210649\tvalid_1's rmse: 0.000501681\tvalid_1's RMSPE: 0.231123\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000452747\ttraining's RMSPE: 0.210214\tvalid_1's rmse: 0.000502224\tvalid_1's RMSPE: 0.229408\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 0.000462257\ttraining's RMSPE: 0.214629\tvalid_1's rmse: 0.000500963\tvalid_1's RMSPE: 0.228832\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000455611\ttraining's RMSPE: 0.210137\tvalid_1's rmse: 0.000500218\tvalid_1's RMSPE: 0.234666\n",
      "[100]\ttraining's rmse: 0.00042116\ttraining's RMSPE: 0.194248\tvalid_1's rmse: 0.000505339\tvalid_1's RMSPE: 0.237068\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 0.00045161\ttraining's RMSPE: 0.208292\tvalid_1's rmse: 0.000499978\tvalid_1's RMSPE: 0.234553\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000454414\ttraining's RMSPE: 0.210582\tvalid_1's rmse: 0.000508292\tvalid_1's RMSPE: 0.234019\n",
      "[100]\ttraining's rmse: 0.000421496\ttraining's RMSPE: 0.195327\tvalid_1's rmse: 0.000511172\tvalid_1's RMSPE: 0.235345\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 0.000446698\ttraining's RMSPE: 0.207006\tvalid_1's rmse: 0.000507589\tvalid_1's RMSPE: 0.233695\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000453033\ttraining's RMSPE: 0.209586\tvalid_1's rmse: 0.000493497\tvalid_1's RMSPE: 0.228759\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 0.000457022\ttraining's RMSPE: 0.211432\tvalid_1's rmse: 0.000492904\tvalid_1's RMSPE: 0.228484\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000455511\ttraining's RMSPE: 0.210522\tvalid_1's rmse: 0.000496922\tvalid_1's RMSPE: 0.231262\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 0.000457268\ttraining's RMSPE: 0.211334\tvalid_1's rmse: 0.000495438\tvalid_1's RMSPE: 0.230572\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.00045704\ttraining's RMSPE: 0.209997\tvalid_1's rmse: 0.000485469\tvalid_1's RMSPE: 0.231053\n",
      "[100]\ttraining's rmse: 0.000422327\ttraining's RMSPE: 0.194047\tvalid_1's rmse: 0.000489111\tvalid_1's RMSPE: 0.232787\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 0.000450252\ttraining's RMSPE: 0.206878\tvalid_1's rmse: 0.000485095\tvalid_1's RMSPE: 0.230875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000453857\ttraining's RMSPE: 0.210818\tvalid_1's rmse: 0.000507178\tvalid_1's RMSPE: 0.231268\n",
      "[100]\ttraining's rmse: 0.00042089\ttraining's RMSPE: 0.195505\tvalid_1's rmse: 0.000510569\tvalid_1's RMSPE: 0.232814\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's rmse: 0.000445735\ttraining's RMSPE: 0.207045\tvalid_1's rmse: 0.000506873\tvalid_1's RMSPE: 0.231129\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000447752\ttraining's RMSPE: 0.20902\tvalid_1's rmse: 0.000527873\tvalid_1's RMSPE: 0.235656\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's rmse: 0.000453131\ttraining's RMSPE: 0.21153\tvalid_1's rmse: 0.000526619\tvalid_1's RMSPE: 0.235096\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000454193\ttraining's RMSPE: 0.210215\tvalid_1's rmse: 0.000495845\tvalid_1's RMSPE: 0.229446\n",
      "[100]\ttraining's rmse: 0.000423163\ttraining's RMSPE: 0.195853\tvalid_1's rmse: 0.000498\tvalid_1's RMSPE: 0.230443\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 0.000454193\ttraining's RMSPE: 0.210215\tvalid_1's rmse: 0.000495845\tvalid_1's RMSPE: 0.229446\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000452004\ttraining's RMSPE: 0.209432\tvalid_1's rmse: 0.000502458\tvalid_1's RMSPE: 0.231481\n",
      "[100]\ttraining's rmse: 0.000418417\ttraining's RMSPE: 0.193869\tvalid_1's rmse: 0.000505932\tvalid_1's RMSPE: 0.233082\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's rmse: 0.000447419\ttraining's RMSPE: 0.207307\tvalid_1's rmse: 0.000502113\tvalid_1's RMSPE: 0.231322\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.00045203\ttraining's RMSPE: 0.209881\tvalid_1's rmse: 0.000502412\tvalid_1's RMSPE: 0.229494\n",
      "[100]\ttraining's rmse: 0.000417347\ttraining's RMSPE: 0.193778\tvalid_1's rmse: 0.000507183\tvalid_1's RMSPE: 0.231673\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 0.00045203\ttraining's RMSPE: 0.209881\tvalid_1's rmse: 0.000502412\tvalid_1's RMSPE: 0.229494\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000456042\ttraining's RMSPE: 0.210336\tvalid_1's rmse: 0.000498329\tvalid_1's RMSPE: 0.233779\n",
      "[100]\ttraining's rmse: 0.000420195\ttraining's RMSPE: 0.193803\tvalid_1's rmse: 0.000501922\tvalid_1's RMSPE: 0.235465\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 0.000454554\ttraining's RMSPE: 0.20965\tvalid_1's rmse: 0.000498027\tvalid_1's RMSPE: 0.233638\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000455949\ttraining's RMSPE: 0.211293\tvalid_1's rmse: 0.000513567\tvalid_1's RMSPE: 0.236448\n",
      "[100]\ttraining's rmse: 0.000421443\ttraining's RMSPE: 0.195302\tvalid_1's rmse: 0.000513366\tvalid_1's RMSPE: 0.236355\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's rmse: 0.00043607\ttraining's RMSPE: 0.20208\tvalid_1's rmse: 0.000510599\tvalid_1's RMSPE: 0.235081\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000455307\ttraining's RMSPE: 0.210638\tvalid_1's rmse: 0.000492729\tvalid_1's RMSPE: 0.228402\n",
      "[100]\ttraining's rmse: 0.000420848\ttraining's RMSPE: 0.194696\tvalid_1's rmse: 0.000498428\tvalid_1's RMSPE: 0.231044\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 0.000448081\ttraining's RMSPE: 0.207296\tvalid_1's rmse: 0.000492358\tvalid_1's RMSPE: 0.22823\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000456235\ttraining's RMSPE: 0.210857\tvalid_1's rmse: 0.000498049\tvalid_1's RMSPE: 0.231787\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's rmse: 0.000459741\ttraining's RMSPE: 0.212477\tvalid_1's rmse: 0.000497845\tvalid_1's RMSPE: 0.231692\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000458152\ttraining's RMSPE: 0.210508\tvalid_1's rmse: 0.000488198\tvalid_1's RMSPE: 0.232352\n",
      "[100]\ttraining's rmse: 0.000422583\ttraining's RMSPE: 0.194165\tvalid_1's rmse: 0.000490523\tvalid_1's RMSPE: 0.233459\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's rmse: 0.00045162\ttraining's RMSPE: 0.207507\tvalid_1's rmse: 0.00048733\tvalid_1's RMSPE: 0.231939\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000453385\ttraining's RMSPE: 0.210599\tvalid_1's rmse: 0.000513246\tvalid_1's RMSPE: 0.234035\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 0.000458723\ttraining's RMSPE: 0.213078\tvalid_1's rmse: 0.000512256\tvalid_1's RMSPE: 0.233584\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000449014\ttraining's RMSPE: 0.209609\tvalid_1's rmse: 0.000524824\tvalid_1's RMSPE: 0.234295\n",
      "[100]\ttraining's rmse: 0.000416931\ttraining's RMSPE: 0.194632\tvalid_1's rmse: 0.000531939\tvalid_1's RMSPE: 0.237471\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 0.000449014\ttraining's RMSPE: 0.209609\tvalid_1's rmse: 0.000524824\tvalid_1's RMSPE: 0.234295\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000453873\ttraining's RMSPE: 0.210067\tvalid_1's rmse: 0.000495339\tvalid_1's RMSPE: 0.229212\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's rmse: 0.000456097\ttraining's RMSPE: 0.211096\tvalid_1's rmse: 0.000495244\tvalid_1's RMSPE: 0.229168\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.00045198\ttraining's RMSPE: 0.209421\tvalid_1's rmse: 0.000505214\tvalid_1's RMSPE: 0.232751\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's rmse: 0.00045951\ttraining's RMSPE: 0.212909\tvalid_1's rmse: 0.000503609\tvalid_1's RMSPE: 0.232011\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000451597\ttraining's RMSPE: 0.20968\tvalid_1's rmse: 0.000505072\tvalid_1's RMSPE: 0.230708\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.000460868\ttraining's RMSPE: 0.213985\tvalid_1's rmse: 0.000503648\tvalid_1's RMSPE: 0.230058\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1702: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000455734\ttraining's RMSPE: 0.210194\tvalid_1's rmse: 0.000503493\tvalid_1's RMSPE: 0.236202\n",
      "[100]\ttraining's rmse: 0.00042066\ttraining's RMSPE: 0.194017\tvalid_1's rmse: 0.00050535\tvalid_1's RMSPE: 0.237073\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 0.00045155\ttraining's RMSPE: 0.208264\tvalid_1's rmse: 0.00050315\tvalid_1's RMSPE: 0.236041\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print('Mean of RMSPE (initial) : ', np.mean(np.array(my_list_rmspe2)), u'\\u00B1', np.std(np.array(my_list_rmspe2)))\n",
    "print('Mean of RMSPE (initial + clusters) : ', np.mean(np.array(my_list_rmspe1)), u'\\u00B1', np.std(np.array(my_list_rmspe1)))\n",
    "print('Mean of RMSPE (normalized + clusters) : ', np.mean(np.array(my_list_rmspe)), u'\\u00B1', np.std(np.array(my_list_rmspe)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean of RMSPE (initial) :  0.23220997646978137 ± 0.002434308917999223\n",
      "Mean of RMSPE (initial + clusters) :  0.23137505065271177 ± 0.0020230195312899543\n",
      "Mean of RMSPE (normalized + clusters) :  0.23102856725662052 ± 0.0020886798188772646\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "e3af083e9e891625b9c68534a23ee03716e10120c7e3db5624663f331b3f95ba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}