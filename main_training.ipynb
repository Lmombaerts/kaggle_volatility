{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code for Kaggle - Optiver Realized Volatility Prediction\n",
    "@LaurentMombaerts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lib Import / Data loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Maths\n",
    "import nolds\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Paths tricks\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Support code\n",
    "from support_file import *\n",
    "\n",
    "datapath = os.path.join(str(Path.home()), 'ownCloud', 'Data', 'Kaggle', 'optiver-realized-volatility-prediction')\n",
    "\n",
    "# Load dataset\n",
    "train = pd.read_csv(os.path.join(datapath,'train.csv')) \n",
    "all_stocks_ids = train['stock_id'].unique()\n",
    "all_time_ids = train['time_id'].unique()\n",
    "\n",
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "train = train[['row_id','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "# Prediction function (chose here which prediction strategy to use)\n",
    "def prediction_function(pred,book_path_train,trade_path_train,targets,book_path_test,trade_path_test):\n",
    "    \n",
    "    if pred == 'naive':\n",
    "        # Naive prediction (persistence model)\n",
    "        prediction = past_realized_volatility_per_stock(list_file=book_path_train,prediction_column_name='pred')\n",
    "        \n",
    "        # Merge and evaluate results\n",
    "        prediction = train.merge(prediction[['row_id','pred']], on = ['row_id'], how = 'left')\n",
    "        print(prediction.head(5))\n",
    "\n",
    "        # Estimate performances\n",
    "        R2 = round(r2_score(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "        RMSPE = round(rmspe(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "\n",
    "        print('--')\n",
    "        print(f'Performance of prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n",
    "        \n",
    "        prediction = prediction.drop(columns=['target'])\n",
    "        prediction = prediction.rename(columns={'pred': 'target'})\n",
    "\n",
    "    if pred == 'stupid_RF':\n",
    "        # Stupid nonlinear regression between persistence and next volatility (random forest)\n",
    "        prediction = stupidForestPrediction(book_path_train=book_path_train,\n",
    "                                            prediction_column_name='pred',\n",
    "                                            train_targets_pd=targets,\n",
    "                                            book_path_test=book_path_test)\n",
    "        \n",
    "    if pred == 'entropy_based':\n",
    "        prediction = entropy_Prediction(book_path_train=book_path_train,\n",
    "                                            prediction_column_name='pred',\n",
    "                                            train_targets_pd=targets,\n",
    "                                            book_path_test=book_path_test)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a prediction code\n",
    "\n",
    "# Glob book file train (contains all paths for each file in this folder)\n",
    "list_order_book_file_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "list_order_book_file_test = glob.glob(os.path.join(datapath,'book_test.parquet','*'))\n",
    "list_trade_file_train = glob.glob(os.path.join(datapath,'trade_train.parquet','*')) \n",
    "list_trade_file_test = glob.glob(os.path.join(datapath,'trade_test.parquet','*'))\n",
    "\n",
    "# Given variables\n",
    "pred = 'entropy_based'\n",
    "book_path_train = list_order_book_file_train\n",
    "trade_path_train = list_trade_file_train\n",
    "targets = train\n",
    "book_path_test = list_order_book_file_test\n",
    "trade_path_test = list_trade_file_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory efficient version\n",
    "#book_all_features = pd.DataFrame()\n",
    "#encoder = np.eye(len(all_stocks_ids))\n",
    "\n",
    "#for file in book_path_train:\n",
    "\n",
    "#file = book_path_train[0]\n",
    "#start = time.time()\n",
    "\n",
    "#book_stock = pd.read_parquet(file)\n",
    "#stock_id = file.split('=')[1]\n",
    "#print('stock id computing = ' + str(stock_id) + '...')\n",
    "\n",
    "# Compute outside of loops\n",
    "#book_stock['wap'] = compute_wap(book_stock)\n",
    "#book_stock['log_return'] = book_stock.groupby(['time_id'])['wap'].apply(log_return)\n",
    "#book_stock = book_stock[~book_stock['log_return'].isnull()]\n",
    "\n",
    "#print(book_stock.head(5))\n",
    "\n",
    "# Compute the square root of the sum of log return squared to get realized volatility\n",
    "#realized_vol = book_stock.groupby(['time_id'])['log_return'].agg(realized_volatility)\n",
    "#df_realized_vol_per_stock = pd.DataFrame(realized_vol)\n",
    "#df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':'realized_volatility'})\n",
    "\n",
    "#entropy = book_stock.groupby(['time_id']).agg(entropy_from_book,last_min=10)\n",
    "#entropy_5 = book_stock.groupby(['time_id']).agg(entropy_from_book,last_min=5)\n",
    "#entropy_2 = book_stock.groupby(['time_id']).agg(entropy_from_book,last_min=2)\n",
    "\n",
    "#print(entropy_2.head(5))\n",
    "\n",
    "#encoded_stock = encoder[np.where(all_stocks_ids == int(stock_id))[0],:]   \n",
    "#encoded_stock_pd = pd.DataFrame(encoded_stock)\n",
    "\n",
    "# Concatenate features, rows\n",
    "#book_features = pd.concat([book_features,encoded_stock_pd],axis=1)\n",
    "#book_all_features = pd.concat([book_all_features,book_features])\n",
    "        \n",
    "#print('Computing one stock entropy took', time.time() - start, 'seconds for stock ', stock_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock id computing = 0\n",
      "Computing one stock entropy took 38.01057291030884 seconds for stock  0\n",
      "stock id computing = 1\n",
      "Computing one stock entropy took 43.15756893157959 seconds for stock  1\n",
      "stock id computing = 10\n",
      "Computing one stock entropy took 46.92417049407959 seconds for stock  10\n",
      "stock id computing = 100\n",
      "Computing one stock entropy took 44.92473387718201 seconds for stock  100\n",
      "stock id computing = 101\n",
      "Computing one stock entropy took 45.46704125404358 seconds for stock  101\n",
      "stock id computing = 102\n",
      "Computing one stock entropy took 44.04671335220337 seconds for stock  102\n",
      "stock id computing = 103\n",
      "Computing one stock entropy took 44.03094959259033 seconds for stock  103\n",
      "stock id computing = 104\n",
      "Computing one stock entropy took 46.51736521720886 seconds for stock  104\n",
      "stock id computing = 105\n",
      "Computing one stock entropy took 49.05899930000305 seconds for stock  105\n",
      "stock id computing = 107\n",
      "Computing one stock entropy took 49.36283206939697 seconds for stock  107\n",
      "stock id computing = 108\n",
      "Computing one stock entropy took 54.60866022109985 seconds for stock  108\n",
      "stock id computing = 109\n",
      "Computing one stock entropy took 51.948610067367554 seconds for stock  109\n",
      "stock id computing = 11\n",
      "Computing one stock entropy took 52.52954053878784 seconds for stock  11\n",
      "stock id computing = 110\n",
      "Computing one stock entropy took 57.876962661743164 seconds for stock  110\n",
      "stock id computing = 111\n",
      "Computing one stock entropy took 61.916996479034424 seconds for stock  111\n",
      "stock id computing = 112\n",
      "Computing one stock entropy took 55.68125557899475 seconds for stock  112\n",
      "stock id computing = 113\n",
      "Computing one stock entropy took 57.32811903953552 seconds for stock  113\n",
      "stock id computing = 114\n",
      "Computing one stock entropy took 57.18414568901062 seconds for stock  114\n",
      "stock id computing = 115\n",
      "Computing one stock entropy took 56.316457986831665 seconds for stock  115\n",
      "stock id computing = 116\n",
      "Computing one stock entropy took 60.62295985221863 seconds for stock  116\n",
      "stock id computing = 118\n",
      "Computing one stock entropy took 60.94458556175232 seconds for stock  118\n",
      "stock id computing = 119\n",
      "Computing one stock entropy took 66.5152382850647 seconds for stock  119\n",
      "stock id computing = 120\n",
      "Computing one stock entropy took 66.27403736114502 seconds for stock  120\n",
      "stock id computing = 122\n",
      "Computing one stock entropy took 65.27846455574036 seconds for stock  122\n",
      "stock id computing = 123\n",
      "Computing one stock entropy took 68.34365725517273 seconds for stock  123\n",
      "stock id computing = 124\n",
      "Computing one stock entropy took 70.82140731811523 seconds for stock  124\n",
      "stock id computing = 125\n",
      "Computing one stock entropy took 71.71782660484314 seconds for stock  125\n",
      "stock id computing = 126\n",
      "Computing one stock entropy took 71.42700934410095 seconds for stock  126\n",
      "stock id computing = 13\n",
      "Computing one stock entropy took 74.46786761283875 seconds for stock  13\n",
      "stock id computing = 14\n",
      "Computing one stock entropy took 78.10620522499084 seconds for stock  14\n",
      "stock id computing = 15\n",
      "Computing one stock entropy took 76.05108451843262 seconds for stock  15\n",
      "stock id computing = 16\n",
      "Computing one stock entropy took 75.66810131072998 seconds for stock  16\n",
      "stock id computing = 17\n",
      "Computing one stock entropy took 77.64151358604431 seconds for stock  17\n",
      "stock id computing = 18\n",
      "Computing one stock entropy took 76.25857329368591 seconds for stock  18\n",
      "stock id computing = 19\n",
      "Computing one stock entropy took 83.35421466827393 seconds for stock  19\n",
      "stock id computing = 2\n",
      "Computing one stock entropy took 87.30782914161682 seconds for stock  2\n",
      "stock id computing = 20\n",
      "Computing one stock entropy took 86.70060276985168 seconds for stock  20\n",
      "stock id computing = 21\n",
      "Computing one stock entropy took 89.48992419242859 seconds for stock  21\n",
      "stock id computing = 22\n",
      "Computing one stock entropy took 87.95629262924194 seconds for stock  22\n",
      "stock id computing = 23\n",
      "Computing one stock entropy took 90.26791095733643 seconds for stock  23\n",
      "stock id computing = 26\n",
      "Computing one stock entropy took 94.22209095954895 seconds for stock  26\n",
      "stock id computing = 27\n",
      "Computing one stock entropy took 91.74564814567566 seconds for stock  27\n",
      "stock id computing = 28\n",
      "Computing one stock entropy took 100.68175792694092 seconds for stock  28\n",
      "stock id computing = 29\n",
      "Computing one stock entropy took 106.15387725830078 seconds for stock  29\n",
      "stock id computing = 3\n",
      "Computing one stock entropy took 102.21500301361084 seconds for stock  3\n",
      "stock id computing = 30\n",
      "Computing one stock entropy took 100.99768447875977 seconds for stock  30\n",
      "stock id computing = 31\n",
      "Computing one stock entropy took 109.14054942131042 seconds for stock  31\n",
      "stock id computing = 32\n",
      "Computing one stock entropy took 110.31628704071045 seconds for stock  32\n",
      "stock id computing = 33\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot embed data of length 1 with embedding dimension 3 and lag 1, minimum required length is 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-50e56f6d91d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#book_features['entropy_last5'] = entropy_from_book(book_stock_time=book_stock_time,last_min=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mbook_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entropy_last2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy_from_book\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mencoded_stock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_stocks_ids\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mentropy_from_book\u001b[1;34m(book_stock_time, last_min)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# Compute sample entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0msampleEntropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_wap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msampleEntropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\nolds\\measures.py\u001b[0m in \u001b[0;36msampen\u001b[1;34m(data, emb_dim, tolerance, dist, debug_plot, debug_data, plot_file)\u001b[0m\n\u001b[0;32m    752\u001b[0m   \u001b[1;31m# not count towards the conditional probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m   \u001b[1;31m# (otherwise first dimension would be n-emb_dim+1 and not n-emb_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m   \u001b[0mtVecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelay_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m   \u001b[0mplot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m   \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\nolds\\measures.py\u001b[0m in \u001b[0;36mdelay_embedding\u001b[1;34m(data, emb_dim, lag)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cannot embed data of length {} with embedding dimension {} \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;33m+\u001b[0m \u001b[1;34m\"and lag {}, minimum required length is {}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m   \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_len\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m   \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot embed data of length 1 with embedding dimension 3 and lag 1, minimum required length is 3"
     ]
    }
   ],
   "source": [
    "book_all_features = pd.DataFrame()\n",
    "encoder = np.eye(len(all_stocks_ids))\n",
    "\n",
    "for file in book_path_train:\n",
    "    start = time.time()\n",
    "\n",
    "    #file = book_path_train[48]\n",
    "    book_stock = pd.read_parquet(file)\n",
    "    stock_id = file.split('=')[1]\n",
    "    print('stock id computing = ' + str(stock_id))\n",
    "    stock_time_ids = book_stock['time_id'].unique()\n",
    "    for time_id in stock_time_ids:     \n",
    "        \n",
    "        # Access book data at this time + stock\n",
    "        book_stock_time = book_stock[book_stock['time_id'] == time_id]\n",
    "\n",
    "        # Create feature matrix\n",
    "        book_features = pd.DataFrame()\n",
    "        book_features['stock_id'] = [stock_id]\n",
    "        book_features['time_id'] = [time_id]\n",
    "        book_features['row_id'] = book_features['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
    "\n",
    "        # Hand-designed features\n",
    "        book_features['volatility'] = realized_volatility_from_book_pd(book_stock_time=book_stock_time)\n",
    "        #book_features['entropy'] = entropy_from_book(book_stock_time=book_stock_time,last_min=10)  \n",
    "        #book_features['entropy_last5'] = entropy_from_book(book_stock_time=book_stock_time,last_min=5)\n",
    "\n",
    "        book_features['entropy_last2'] = entropy_from_book(book_stock_time=book_stock_time,last_min=2)\n",
    "\n",
    "        encoded_stock = encoder[np.where(all_stocks_ids == int(stock_id))[0],:]   \n",
    "        encoded_stock_pd = pd.DataFrame(encoded_stock)\n",
    "\n",
    "        # Concatenate features, rows\n",
    "        #book_features = pd.concat([book_features,encoded_stock_pd],axis=1)   \n",
    "        book_all_features = pd.concat([book_all_features,book_features])\n",
    "    \n",
    "    print('Computing one stock entropy took', time.time() - start, 'seconds for stock ', stock_id)\n",
    "\n",
    "# Merge targets\n",
    "#book_all_features = book_all_features.merge(train, on = ['row_id'])\n",
    "book_all_features = train.merge(book_all_features, on = ['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>volatility</th>\n",
       "      <th>entropy_last2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.357092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.173592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.076961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4329</td>\n",
       "      <td>20-4329</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.582752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4361</td>\n",
       "      <td>20-4361</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.646385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4364</td>\n",
       "      <td>20-4364</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.473661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4367</td>\n",
       "      <td>20-4367</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.275590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4371</td>\n",
       "      <td>20-4371</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.748410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138409 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id   row_id  volatility  entropy_last2    0    1    2    3  \\\n",
       "0         0        5      0-5    0.004499       0.357092  1.0  0.0  0.0  0.0   \n",
       "0         0       11     0-11    0.001204       0.173592  1.0  0.0  0.0  0.0   \n",
       "0         0       16     0-16    0.002369       0.066508  1.0  0.0  0.0  0.0   \n",
       "0         0       31     0-31    0.002574       0.076961  1.0  0.0  0.0  0.0   \n",
       "0         0       62     0-62    0.001894       0.164630  1.0  0.0  0.0  0.0   \n",
       "..      ...      ...      ...         ...            ...  ...  ...  ...  ...   \n",
       "0        20     4329  20-4329    0.002262       0.582752  0.0  0.0  0.0  0.0   \n",
       "0        20     4361  20-4361    0.001112       0.646385  0.0  0.0  0.0  0.0   \n",
       "0        20     4364  20-4364    0.002585       0.473661  0.0  0.0  0.0  0.0   \n",
       "0        20     4367  20-4367    0.001945       0.275590  0.0  0.0  0.0  0.0   \n",
       "0        20     4371  20-4371    0.003609       0.748410  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      4  ...  102  103  104  105  106  107  108  109  110  111  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[138409 rows x 117 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Persistence model perf : 0.39322701284497674\n",
      "New model perf :  0.32213065513839995\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X = book_all_features.drop(['row_id','target','stock_id','time_id'],axis=1)\n",
    "y = book_all_features['target']\n",
    "\n",
    "x_test = X # to change\n",
    "\n",
    "xgboost_default = xgb.XGBRegressor(random_state=0)\n",
    "xgboost_default.fit(X,y)\n",
    "\n",
    "yhat = xgboost_default.predict(x_test)\n",
    "print('Persistence model perf :', rmspe(y,book_all_features['volatility']))\n",
    "print('New model perf : ', rmspe(y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main evaluation code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob book file train (contains all paths for each file in this folder)\n",
    "list_order_book_file_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "list_order_book_file_test = glob.glob(os.path.join(datapath,'book_test.parquet','*'))\n",
    "list_trade_file_train = glob.glob(os.path.join(datapath,'trade_train.parquet','*')) \n",
    "list_trade_file_test = glob.glob(os.path.join(datapath,'trade_test.parquet','*'))\n",
    "\n",
    "# Compute predictions\n",
    "prediction = prediction_function(pred='stupid_RF',\n",
    "                                 book_path_train=list_order_book_file_train,\n",
    "                                 trade_path_train=list_trade_file_train,\n",
    "                                 targets=train,\n",
    "                                 book_path_test=list_order_book_file_test,\n",
    "                                 trade_path_test=list_trade_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
