{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code for Kaggle - Optiver Realized Volatility Prediction\n",
    "@LaurentMombaerts @VladimirLevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE TO SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "machine = 'local'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lib Import / Data loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Parallel Computing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Maths\n",
    "from scipy.interpolate import interp1d\n",
    "# from arch import arch_model\n",
    "\n",
    "# Paths tricks\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Support code\n",
    "from support_file import *\n",
    "from information_measures import *\n",
    "\n",
    "if machine == 'local':\n",
    "    datapath = os.path.join(str(Path.home()), 'ownCloud', 'Data', 'Kaggle', 'optiver-realized-volatility-prediction')\n",
    "\n",
    "    # Load dataset\n",
    "    train = pd.read_csv(os.path.join(datapath,'train.csv')) \n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    # Load test ids\n",
    "    test = pd.read_csv(os.path.join(datapath,'test.csv'))\n",
    "    all_stocks_ids_test = test['stock_id'].unique()\n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "elif machine == 'kaggle':\n",
    "    \n",
    "    # Load dataset\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv') \n",
    "    all_stocks_ids_test = test['stock_id'].unique()\n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "    datapath = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel_timeSplit(X,y,groups,model,splits):\n",
    "    \n",
    "    rmspe_list = []\n",
    "    \n",
    "    for random_split in range(splits):\n",
    "        gss = GroupShuffleSplit(n_splits=1, train_size=.80, random_state=random_split)\n",
    "        gss.get_n_splits()\n",
    "\n",
    "        for train, test in gss.split(X, y, groups):\n",
    "            # CV definition\n",
    "            X_train, X_test = X.iloc[train,:], X.iloc[test,:]\n",
    "            y_train, y_test = y[train],y[test]\n",
    "            \n",
    "            # Add other stocks volatility at same time id and this stock overall volatility\n",
    "            X_test = get_time_stock(X_test).drop(['row_id','time_id','stock_id'],axis=1)\n",
    "            X_train = get_time_stock(X_train).drop(['row_id','time_id','stock_id'],axis=1)\n",
    "    \n",
    "            # Model definition\n",
    "            model.fit(X_train,y_train)\n",
    "            yhat = model.predict(X_test)\n",
    "    \n",
    "            # Estimate perf\n",
    "            rmspe_list.append(rmspe(y_test, yhat))\n",
    "            \n",
    "    return rmspe_list\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    \n",
    "    df['stock_id'] = [df['row_id'][i].split('-')[0] for i in range(df.shape[0])]\n",
    "    df['time_id'] = [df['row_id'][i].split('-')[1] for i in range(df.shape[0])]\n",
    "            \n",
    "    # Get realized volatility columns\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', \n",
    "                'log_return3_realized_volatility', 'log_return4_realized_volatility', \n",
    "                'log_returnMidprice_realized_volatility',\n",
    "                'log_return1_realized_volatility_480', 'log_return2_realized_volatility_480',\n",
    "                'log_return3_realized_volatility_480', 'log_return4_realized_volatility_480',\n",
    "                'log_returnMidprice_realized_volatility_480',\n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300',\n",
    "                'log_return3_realized_volatility_300', 'log_return4_realized_volatility_300',\n",
    "                'log_returnMidprice_realized_volatility_300', \n",
    "                'log_return1_realized_volatility_120', 'log_return2_realized_volatility_120',\n",
    "                'log_return3_realized_volatility_120', 'log_return4_realized_volatility_120',\n",
    "                'log_returnMidprice_realized_volatility_120',         \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_480', \n",
    "                'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_120']\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the time id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    \n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_CatBoost_cv(df_features_train,targets,splits):\n",
    "    \n",
    "    model = CatBoostRegressor(verbose=0)\n",
    "\n",
    "    # Data input / output definition\n",
    "    X = df_features_train.fillna(0)\n",
    "    y = targets\n",
    "    time_id_groups = [df_features_train['row_id'][i].split('-')[1] for i in range(df_features_train.shape[0])]\n",
    "   \n",
    "    rmspe_list = trainModel_timeSplit(X,y,time_id_groups,model,splits)\n",
    "    \n",
    "    return rmspe_list\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    \n",
    "    y_true = lgb_train.get_label()\n",
    "    \n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_lgbm_cv(df_features_train,targets,splits):\n",
    "    \n",
    "    # Data input / output definition\n",
    "    X = df_features_train.fillna(0)\n",
    "    y = targets\n",
    "    time_id_groups = [df_features_train['row_id'][i].split('-')[1] for i in range(df_features_train.shape[0])]\n",
    "\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'num_leaves': 100,\n",
    "      'n_jobs': -1,\n",
    "      'learning_rate': 0.1,\n",
    "      'feature_fraction': 0.8,\n",
    "      'bagging_fraction': 0.8,\n",
    "      'verbose': -1\n",
    "    }\n",
    "\n",
    "    rmspe_list = []\n",
    "\n",
    "    for random_split in range(splits):\n",
    "        gss = GroupShuffleSplit(n_splits=1, train_size=.80, random_state=random_split)\n",
    "        gss.get_n_splits()\n",
    "\n",
    "        for train, test in gss.split(X, y, time_id_groups):\n",
    "            # CV definition\n",
    "            x_train, x_val = X.iloc[train,:].reset_index(drop=True), X.iloc[test,:].reset_index(drop=True)\n",
    "            y_train, y_val = y[train].reset_index(drop=True),y[test].reset_index(drop=True)\n",
    "\n",
    "            # Add other stocks volatility at same time id and this stock overall volatility\n",
    "            x_val = get_time_stock(x_val).drop(['row_id','time_id'],axis=1)\n",
    "            x_val['stock_id'] = x_val['stock_id'].astype(int)\n",
    "            x_train = get_time_stock(x_train).drop(['row_id','time_id'],axis=1)\n",
    "            x_train['stock_id'] = x_train['stock_id'].astype(int)\n",
    "\n",
    "            # Root mean squared percentage error weights\n",
    "            train_weights = 1 / np.square(y_train)\n",
    "            val_weights = 1 / np.square(y_val)\n",
    "            train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "            val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights, categorical_feature = ['stock_id'])\n",
    "\n",
    "            # Model definition\n",
    "            model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 10000, \n",
    "                          early_stopping_rounds = 50, \n",
    "                          verbose_eval = 50,\n",
    "                          feval = feval_rmspe)\n",
    "\n",
    "            yhat = model.predict(x_val) \n",
    "\n",
    "            # Estimate perf\n",
    "            rmspe_list.append(rmspe(y_val, yhat))\n",
    "            \n",
    "    return rmspe_list\n",
    "\n",
    "def train_lgbm(df_features_train,targets):\n",
    "    \n",
    "    # Data input / output definition\n",
    "    X = df_features_train.fillna(0)\n",
    "    X['stock_id'] = X['stock_id'].astype(int)\n",
    "    y = targets\n",
    "\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'num_leaves': 100,\n",
    "      'n_jobs': -1,\n",
    "      'learning_rate': 0.1,\n",
    "      'feature_fraction': 0.8,\n",
    "      'bagging_fraction': 0.8,\n",
    "      'verbose': -1\n",
    "    }\n",
    "\n",
    "    X['stock_id'] = X['stock_id'].astype(int)\n",
    "            \n",
    "    # Root mean squared percentage error weights\n",
    "    train_weights = 1 / np.square(y)\n",
    "    train_dataset = lgb.Dataset(X, y, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "\n",
    "    # Model definition\n",
    "    model = lgb.train(params = params, \n",
    "                  train_set = train_dataset, \n",
    "                  num_boost_round = 50, \n",
    "                  verbose_eval = 50,\n",
    "                  feval = feval_rmspe)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "# Prediction function (chose here which prediction strategy to use)\n",
    "def prediction_function(pred, machine, targets, all_stocks_ids, datapath, test, all_stocks_ids_test):\n",
    "        \n",
    "    if pred == 'entropy':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_train['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent_withoutEncoding':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent_withoutEncoding_wTrades':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "        \n",
    "    if pred == 'garch':\n",
    "        \n",
    "        if machine == 'local':\n",
    "            book_path_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "            \n",
    "            # fit garch and predict\n",
    "            prediction = garch_volatility_per_stock(list_file=book_path_train, prediction_column_name='pred')\n",
    "            \n",
    "            # Merge and evaluate results\n",
    "            prediction = train.merge(prediction[['row_id','pred']], on = ['row_id'], how = 'left')\n",
    "            prediction = prediction[prediction.pred.notnull()]\n",
    "\n",
    "            # Estimate performances\n",
    "            R2 = round(r2_score(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "            RMSPE = round(rmspe(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "\n",
    "            print('--')\n",
    "            print(f'Performance of prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n",
    "\n",
    "            prediction = prediction.drop(columns=['target'])\n",
    "            prediction = prediction.rename(columns={'pred': 'target'})\n",
    "            \n",
    "            return prediction\n",
    "        \n",
    "\n",
    "    if pred == 'test_2807':\n",
    "        if machine == 'local':\n",
    "\n",
    "            # Load data\n",
    "            df_features_test = computeFeatures_2807(machine=machine, dataset='test', all_stocks_ids=[0], datapath=datapath).fillna(0)\n",
    "            df_features_train = computeFeatures_2807(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath).fillna(0)\n",
    "\n",
    "            # saving features to the .csv file\n",
    "            print('['+time.strftime('%X')+']', 'Saving features to .parquet files ...') # print also time\n",
    "            df_features_train.to_parquet('df_features_train.parquet')\n",
    "            df_features_test.to_parquet('df_features_test.parquet')\n",
    "                              \n",
    "            # Modelling\n",
    "            start = time.time()\n",
    "            print('['+time.strftime('%X')+']', 'Model Training on splits...')\n",
    "            \n",
    "            # Model list\n",
    "            #list_rmspe = train_CatBoost_cv(df_features_train=df_features_train,targets=targets,splits=10)\n",
    "            list_rmspe = train_lgbm_cv(df_features_train=df_features_train,targets=targets,splits=10)\n",
    "            \n",
    "            print('['+time.strftime('%X')+']', 'Training on splits took ',  time.time() - start, 'seconds')\n",
    "            \n",
    "            # Print results\n",
    "            print(list_rmspe)\n",
    "            print('Mean of RMSPE : ', np.mean(np.array(list_rmspe)), ' +- ', np.std(np.array(list_rmspe)))\n",
    "            \n",
    "            return df_features_train # Returns the feature in local mode for further use\n",
    "\n",
    "        # Features computation\n",
    "        df_features_test = computeFeatures_2807(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids_test, datapath=datapath).fillna(0)\n",
    "        df_features_test = test.merge(df_features_test, on = ['row_id'], how = 'left') # Should ensure order of predictions\n",
    "        df_features_train = computeFeatures_2807(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath).fillna(0)\n",
    "        rows_id_to_merge = df_features_test['row_id'].copy()\n",
    "        \n",
    "        # Add other stocks volatility at same time id and this stock overall volatility\n",
    "        df_features_test = get_time_stock(df_features_test).drop(['row_id','time_id'],axis=1)\n",
    "        df_features_test['stock_id'] = df_features_test['stock_id'].astype(int)\n",
    "        df_features_train = get_time_stock(df_features_train).drop(['row_id','time_id'],axis=1)\n",
    "        \n",
    "        # Optimized model\n",
    "        model = train_lgbm(df_features_train=df_features_train, targets=targets)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        yhat = model.predict(df_features_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([rows_id_to_merge,yhat_pd],axis=1)    \n",
    "\n",
    "        \n",
    "        \n",
    "    return submission_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 56.1min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 251.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:35:28] Saving features to .parquet files ...\n",
      "[13:35:31] Model Training on splits...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000430452\ttraining's RMSPE: 0.199556\tvalid_1's rmse: 0.000483344\tvalid_1's RMSPE: 0.222175\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 0.000446422\ttraining's RMSPE: 0.20696\tvalid_1's rmse: 0.000483097\tvalid_1's RMSPE: 0.222062\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000427559\ttraining's RMSPE: 0.198997\tvalid_1's rmse: 0.000509167\tvalid_1's RMSPE: 0.230249\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 0.000435997\ttraining's RMSPE: 0.202924\tvalid_1's rmse: 0.000508003\tvalid_1's RMSPE: 0.229722\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000429524\ttraining's RMSPE: 0.198406\tvalid_1's rmse: 0.000481776\tvalid_1's RMSPE: 0.224683\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.000440327\ttraining's RMSPE: 0.203396\tvalid_1's rmse: 0.000481123\tvalid_1's RMSPE: 0.224378\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000430745\ttraining's RMSPE: 0.199368\tvalid_1's rmse: 0.000489522\tvalid_1's RMSPE: 0.226494\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's rmse: 0.000432554\ttraining's RMSPE: 0.200205\tvalid_1's rmse: 0.000489336\tvalid_1's RMSPE: 0.226408\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000429982\ttraining's RMSPE: 0.199019\tvalid_1's rmse: 0.000504957\tvalid_1's RMSPE: 0.233616\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's rmse: 0.000449997\ttraining's RMSPE: 0.208283\tvalid_1's rmse: 0.000503903\tvalid_1's RMSPE: 0.233128\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000431518\ttraining's RMSPE: 0.199678\tvalid_1's rmse: 0.000481392\tvalid_1's RMSPE: 0.222945\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's rmse: 0.000443736\ttraining's RMSPE: 0.205332\tvalid_1's rmse: 0.000481175\tvalid_1's RMSPE: 0.222845\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000425025\ttraining's RMSPE: 0.198485\tvalid_1's rmse: 0.000512093\tvalid_1's RMSPE: 0.228234\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's rmse: 0.000444131\ttraining's RMSPE: 0.207407\tvalid_1's rmse: 0.000510206\tvalid_1's RMSPE: 0.227393\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000430062\ttraining's RMSPE: 0.199584\tvalid_1's rmse: 0.000505338\tvalid_1's RMSPE: 0.231292\n",
      "[100]\ttraining's rmse: 0.000392923\ttraining's RMSPE: 0.182349\tvalid_1's rmse: 0.000510499\tvalid_1's RMSPE: 0.233654\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 0.00042574\ttraining's RMSPE: 0.197578\tvalid_1's rmse: 0.000505088\tvalid_1's RMSPE: 0.231177\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000425626\ttraining's RMSPE: 0.198055\tvalid_1's rmse: 0.000496055\tvalid_1's RMSPE: 0.224524\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's rmse: 0.000433745\ttraining's RMSPE: 0.201833\tvalid_1's rmse: 0.000494303\tvalid_1's RMSPE: 0.223731\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000429545\ttraining's RMSPE: 0.198508\tvalid_1's rmse: 0.000490185\tvalid_1's RMSPE: 0.228185\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's rmse: 0.000436169\ttraining's RMSPE: 0.20157\tvalid_1's rmse: 0.000489895\tvalid_1's RMSPE: 0.228051\n",
      "[13:44:02] Training on splits took  511.4371693134308 seconds\n",
      "[0.22206159998121108, 0.22972222208558, 0.22437815384611798, 0.22640796115376602, 0.23312775356021675, 0.222844595594713, 0.2273928156078972, 0.23117741284613638, 0.22373063319409148, 0.22805058745746867]\n",
      "Mean of RMSPE :  0.22688937353271985  +-  0.0035087721199688732\n"
     ]
    }
   ],
   "source": [
    "# New sub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_submission = prediction_function(pred='test_2807',machine=machine,targets=train['target'],all_stocks_ids=all_stocks_ids, datapath=datapath, test=test, all_stocks_ids_test=all_stocks_ids_test)\n",
    "if machine == 'kaggle':\n",
    "    df_submission.to_csv('submission.csv',index=False)\n",
    "else:\n",
    "    df_submission.iloc[0:10,:].to_csv('features_train_head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wap_sum</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>wap_std</th>\n",
       "      <th>wap2_sum</th>\n",
       "      <th>wap2_mean</th>\n",
       "      <th>wap2_std</th>\n",
       "      <th>wap3_sum</th>\n",
       "      <th>wap3_mean</th>\n",
       "      <th>wap3_std</th>\n",
       "      <th>wap4_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>trade_size_sum_120</th>\n",
       "      <th>trade_order_count_sum_120</th>\n",
       "      <th>trade_order_count_mean_120</th>\n",
       "      <th>trade_roll_measure_120</th>\n",
       "      <th>trade_roll_impact_120</th>\n",
       "      <th>trade_mkt_impact_120</th>\n",
       "      <th>trade_amihud_120</th>\n",
       "      <th>trade_traded_volume_120</th>\n",
       "      <th>trade_avg_trade_size_120</th>\n",
       "      <th>vpin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303.125061</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>303.105539</td>\n",
       "      <td>1.003661</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>303.146936</td>\n",
       "      <td>1.003798</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>303.134863</td>\n",
       "      <td>...</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>6.382619e-08</td>\n",
       "      <td>3.394071e-06</td>\n",
       "      <td>4.216972e-07</td>\n",
       "      <td>3190.139181</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>0.923509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.047768</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>200.041171</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>200.040851</td>\n",
       "      <td>1.000204</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>200.035611</td>\n",
       "      <td>...</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>3.589880e-07</td>\n",
       "      <td>5.943633e-06</td>\n",
       "      <td>6.228642e-07</td>\n",
       "      <td>1289.353432</td>\n",
       "      <td>22.614035</td>\n",
       "      <td>0.825187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187.913849</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>187.939824</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>187.897375</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>187.923063</td>\n",
       "      <td>...</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>1.886683e-07</td>\n",
       "      <td>3.891099e-06</td>\n",
       "      <td>1.175237e-06</td>\n",
       "      <td>2158.608928</td>\n",
       "      <td>31.779412</td>\n",
       "      <td>0.995675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.859781</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>119.835941</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>119.884240</td>\n",
       "      <td>0.999035</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>119.870163</td>\n",
       "      <td>...</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>3.764258e-07</td>\n",
       "      <td>3.631721e-06</td>\n",
       "      <td>1.152450e-06</td>\n",
       "      <td>1959.605547</td>\n",
       "      <td>33.254237</td>\n",
       "      <td>0.966280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.932865</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>175.934256</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>175.912533</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>175.928283</td>\n",
       "      <td>...</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>2.023833e-07</td>\n",
       "      <td>2.770568e-06</td>\n",
       "      <td>1.531391e-07</td>\n",
       "      <td>1790.254496</td>\n",
       "      <td>20.123596</td>\n",
       "      <td>0.924680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>309.870466</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>309.871372</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>309.812308</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>309.778634</td>\n",
       "      <td>...</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.172414</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>9.479032e-08</td>\n",
       "      <td>4.542918e-06</td>\n",
       "      <td>4.704802e-07</td>\n",
       "      <td>2568.838117</td>\n",
       "      <td>24.951456</td>\n",
       "      <td>0.886608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>223.552143</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>223.580314</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>223.480899</td>\n",
       "      <td>1.002156</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>223.505486</td>\n",
       "      <td>...</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.057143</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>2.134959e-07</td>\n",
       "      <td>5.329830e-06</td>\n",
       "      <td>2.091255e-06</td>\n",
       "      <td>2327.828627</td>\n",
       "      <td>15.802721</td>\n",
       "      <td>0.785283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>256.277050</td>\n",
       "      <td>1.001082</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>256.255056</td>\n",
       "      <td>1.000996</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>256.168899</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>256.146066</td>\n",
       "      <td>...</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>2.072699e-07</td>\n",
       "      <td>3.641015e-06</td>\n",
       "      <td>3.455508e-07</td>\n",
       "      <td>3742.254714</td>\n",
       "      <td>38.163265</td>\n",
       "      <td>0.857006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>399.721736</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>399.714332</td>\n",
       "      <td>1.001790</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>399.779362</td>\n",
       "      <td>1.001953</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>399.775385</td>\n",
       "      <td>...</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>2.852941</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1.950722e-08</td>\n",
       "      <td>1.610208e-06</td>\n",
       "      <td>2.399811e-08</td>\n",
       "      <td>9406.795437</td>\n",
       "      <td>40.123932</td>\n",
       "      <td>0.860831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>217.058919</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>217.079726</td>\n",
       "      <td>1.000367</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>217.059081</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>217.069038</td>\n",
       "      <td>...</td>\n",
       "      <td>4289.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>1.705715e-08</td>\n",
       "      <td>9.988507e-07</td>\n",
       "      <td>1.918151e-07</td>\n",
       "      <td>5326.415054</td>\n",
       "      <td>49.305556</td>\n",
       "      <td>0.883043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows Ã— 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wap_sum  wap_mean   wap_std    wap2_sum  wap2_mean  wap2_std  \\\n",
       "0       303.125061  1.003725  0.000693  303.105539   1.003661  0.000781   \n",
       "1       200.047768  1.000239  0.000262  200.041171   1.000206  0.000272   \n",
       "2       187.913849  0.999542  0.000864  187.939824   0.999680  0.000862   \n",
       "3       119.859781  0.998832  0.000757  119.835941   0.998633  0.000656   \n",
       "4       175.932865  0.999619  0.000258  175.934256   0.999626  0.000317   \n",
       "...            ...       ...       ...         ...        ...       ...   \n",
       "428927  309.870466  0.999582  0.000486  309.871372   0.999585  0.000613   \n",
       "428928  223.552143  1.002476  0.001264  223.580314   1.002602  0.001303   \n",
       "428929  256.277050  1.001082  0.000466  256.255056   1.000996  0.000599   \n",
       "428930  399.721736  1.001809  0.000456  399.714332   1.001790  0.000507   \n",
       "428931  217.058919  1.000272  0.000384  217.079726   1.000367  0.000465   \n",
       "\n",
       "          wap3_sum  wap3_mean  wap3_std    wap4_sum  ...  trade_size_sum_120  \\\n",
       "0       303.146936   1.003798  0.000652  303.134863  ...              2411.0   \n",
       "1       200.040851   1.000204  0.000278  200.035611  ...              1174.0   \n",
       "2       187.897375   0.999454  0.000779  187.923063  ...              2024.0   \n",
       "3       119.884240   0.999035  0.000733  119.870163  ...              1631.0   \n",
       "4       175.912533   0.999503  0.000312  175.928283  ...              1574.0   \n",
       "...            ...        ...       ...         ...  ...                 ...   \n",
       "428927  309.812308   0.999395  0.000594  309.778634  ...              1432.0   \n",
       "428928  223.480899   1.002156  0.001341  223.505486  ...              1781.0   \n",
       "428929  256.168899   1.000660  0.000558  256.146066  ...              3631.0   \n",
       "428930  399.779362   1.001953  0.000429  399.775385  ...              8090.0   \n",
       "428931  217.059081   1.000272  0.000387  217.069038  ...              4289.0   \n",
       "\n",
       "        trade_order_count_sum_120  trade_order_count_mean_120  \\\n",
       "0                            82.0                    2.411765   \n",
       "1                            50.0                    2.000000   \n",
       "2                            60.0                    2.857143   \n",
       "3                            50.0                    4.545455   \n",
       "4                            75.0                    4.166667   \n",
       "...                           ...                         ...   \n",
       "428927                       63.0                    2.172414   \n",
       "428928                      107.0                    3.057143   \n",
       "428929                       92.0                    2.875000   \n",
       "428930                      194.0                    2.852941   \n",
       "428931                       89.0                    2.966667   \n",
       "\n",
       "        trade_roll_measure_120  trade_roll_impact_120  trade_mkt_impact_120  \\\n",
       "0                     0.000204           6.382619e-08          3.394071e-06   \n",
       "1                     0.000463           3.589880e-07          5.943633e-06   \n",
       "2                     0.000407           1.886683e-07          3.891099e-06   \n",
       "3                     0.000738           3.764258e-07          3.631721e-06   \n",
       "4                     0.000362           2.023833e-07          2.770568e-06   \n",
       "...                        ...                    ...                   ...   \n",
       "428927                0.000244           9.479032e-08          4.542918e-06   \n",
       "428928                0.000497           2.134959e-07          5.329830e-06   \n",
       "428929                0.000776           2.072699e-07          3.641015e-06   \n",
       "428930                0.000184           1.950722e-08          1.610208e-06   \n",
       "428931                0.000091           1.705715e-08          9.988507e-07   \n",
       "\n",
       "        trade_amihud_120  trade_traded_volume_120  trade_avg_trade_size_120  \\\n",
       "0           4.216972e-07              3190.139181                 28.900000   \n",
       "1           6.228642e-07              1289.353432                 22.614035   \n",
       "2           1.175237e-06              2158.608928                 31.779412   \n",
       "3           1.152450e-06              1959.605547                 33.254237   \n",
       "4           1.531391e-07              1790.254496                 20.123596   \n",
       "...                  ...                      ...                       ...   \n",
       "428927      4.704802e-07              2568.838117                 24.951456   \n",
       "428928      2.091255e-06              2327.828627                 15.802721   \n",
       "428929      3.455508e-07              3742.254714                 38.163265   \n",
       "428930      2.399811e-08              9406.795437                 40.123932   \n",
       "428931      1.918151e-07              5326.415054                 49.305556   \n",
       "\n",
       "            vpin  \n",
       "0       0.923509  \n",
       "1       0.825187  \n",
       "2       0.995675  \n",
       "3       0.966280  \n",
       "4       0.924680  \n",
       "...          ...  \n",
       "428927  0.886608  \n",
       "428928  0.785283  \n",
       "428929  0.857006  \n",
       "428930  0.860831  \n",
       "428931  0.883043  \n",
       "\n",
       "[428932 rows x 278 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3af083e9e891625b9c68534a23ee03716e10120c7e3db5624663f331b3f95ba"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
