{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code for Kaggle - Optiver Realized Volatility Prediction\n",
    "@LaurentMombaerts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lib Import / Data loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Maths\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Paths tricks\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Support code\n",
    "from support_file import *\n",
    "from information_measures import *\n",
    "\n",
    "###########################\n",
    "machine = 'local'\n",
    "###########################\n",
    "\n",
    "if machine == 'local':\n",
    "    datapath = os.path.join(str(Path.home()), 'ownCloud', 'Data', 'Kaggle', 'optiver-realized-volatility-prediction')\n",
    "\n",
    "    # Load dataset\n",
    "    train = pd.read_csv(os.path.join(datapath,'train.csv')) \n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    # Load test ids\n",
    "    test = pd.read_csv(os.path.join(datapath,'test.csv'))\n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "elif machine == 'kaggle':\n",
    "    \n",
    "    # Load dataset\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv') \n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "# Prediction function (chose here which prediction strategy to use)\n",
    "def prediction_function(pred, machine, targets, all_stocks_ids):\n",
    "        \n",
    "    if pred == 'entropy':\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids)\n",
    "        df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        catboost_default = CatBoostRegressor(verbose=0)\n",
    "        catboost_default.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = catboost_default.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "    return submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = prediction_function(pred='entropy',machine='local',targets=train['target'],all_stocks_ids=all_stocks_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 78.40056204795837 seconds for stock  0\n",
      "Computing one stock took 78.00121140480042 seconds for stock  1\n",
      "Computing one stock took 80.0335214138031 seconds for stock  2\n",
      "Computing one stock took 77.10368728637695 seconds for stock  3\n",
      "Computing one stock took 76.08033490180969 seconds for stock  4\n",
      "Computing one stock took 74.6215660572052 seconds for stock  5\n",
      "Computing one stock took 76.14969182014465 seconds for stock  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 70.95528101921082 seconds for stock  7\n",
      "Computing one stock took 72.4843225479126 seconds for stock  8\n",
      "Computing one stock took 69.70015931129456 seconds for stock  9\n",
      "Computing one stock took 74.99949765205383 seconds for stock  10\n",
      "Computing one stock took 71.16744899749756 seconds for stock  11\n",
      "Computing one stock took 74.54515361785889 seconds for stock  13\n",
      "Computing one stock took 74.01098704338074 seconds for stock  14\n",
      "Computing one stock took 72.29604053497314 seconds for stock  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 68.91552662849426 seconds for stock  16\n",
      "Computing one stock took 73.71882963180542 seconds for stock  17\n",
      "Computing one stock took 71.53120589256287 seconds for stock  18\n",
      "Computing one stock took 74.39288830757141 seconds for stock  19\n",
      "Computing one stock took 75.80600929260254 seconds for stock  20\n",
      "Computing one stock took 76.04484176635742 seconds for stock  21\n",
      "Computing one stock took 71.34460830688477 seconds for stock  22\n",
      "Computing one stock took 71.54472756385803 seconds for stock  23\n",
      "Computing one stock took 76.63270950317383 seconds for stock  26\n",
      "Computing one stock took 72.77859354019165 seconds for stock  27\n",
      "Computing one stock took 73.19689536094666 seconds for stock  28\n",
      "Computing one stock took 74.00018978118896 seconds for stock  29\n",
      "Computing one stock took 71.16373562812805 seconds for stock  30\n",
      "Computing one stock took 72.95074248313904 seconds for stock  31\n",
      "Computing one stock took 73.59148073196411 seconds for stock  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 67.9111602306366 seconds for stock  33\n",
      "Computing one stock took 74.64365911483765 seconds for stock  34\n",
      "Computing one stock took 77.53510332107544 seconds for stock  35\n",
      "Computing one stock took 74.66532444953918 seconds for stock  36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 71.06928706169128 seconds for stock  37\n",
      "Computing one stock took 72.09638714790344 seconds for stock  38\n",
      "Computing one stock took 79.92956733703613 seconds for stock  39\n",
      "Computing one stock took 70.34637403488159 seconds for stock  40\n",
      "Computing one stock took 73.83815932273865 seconds for stock  41\n",
      "Computing one stock took 74.81204462051392 seconds for stock  42\n",
      "Computing one stock took 75.82460713386536 seconds for stock  43\n",
      "Computing one stock took 5411.685176610947 seconds for stock  44\n",
      "Computing one stock took 76.66262698173523 seconds for stock  46\n",
      "Computing one stock took 73.4518723487854 seconds for stock  47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 71.74880480766296 seconds for stock  48\n",
      "Computing one stock took 73.98410868644714 seconds for stock  50\n",
      "Computing one stock took 76.69444346427917 seconds for stock  51\n",
      "Computing one stock took 75.22188568115234 seconds for stock  52\n",
      "Computing one stock took 74.59291529655457 seconds for stock  53\n",
      "Computing one stock took 72.48686003684998 seconds for stock  55\n",
      "Computing one stock took 76.00697565078735 seconds for stock  56\n",
      "Computing one stock took 72.14395666122437 seconds for stock  58\n",
      "Computing one stock took 76.70502424240112 seconds for stock  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 73.61695098876953 seconds for stock  60\n",
      "Computing one stock took 77.13644814491272 seconds for stock  61\n",
      "Computing one stock took 75.95353507995605 seconds for stock  62\n",
      "Computing one stock took 76.01673579216003 seconds for stock  63\n",
      "Computing one stock took 77.28658199310303 seconds for stock  64\n",
      "Computing one stock took 73.42819595336914 seconds for stock  66\n",
      "Computing one stock took 78.18217444419861 seconds for stock  67\n",
      "Computing one stock took 77.50853395462036 seconds for stock  68\n",
      "Computing one stock took 77.48137879371643 seconds for stock  69\n",
      "Computing one stock took 76.56007957458496 seconds for stock  70\n",
      "Computing one stock took 72.46697616577148 seconds for stock  72\n",
      "Computing one stock took 78.35754084587097 seconds for stock  73\n",
      "Computing one stock took 74.36866235733032 seconds for stock  74\n",
      "Computing one stock took 70.91724133491516 seconds for stock  75\n",
      "Computing one stock took 75.04919099807739 seconds for stock  76\n",
      "Computing one stock took 74.99717569351196 seconds for stock  77\n",
      "Computing one stock took 71.39129185676575 seconds for stock  78\n",
      "Computing one stock took 71.72609257698059 seconds for stock  80\n",
      "Computing one stock took 75.89190244674683 seconds for stock  81\n",
      "Computing one stock took 73.52088117599487 seconds for stock  82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 69.38282322883606 seconds for stock  83\n",
      "Computing one stock took 73.48994994163513 seconds for stock  84\n",
      "Computing one stock took 75.46828055381775 seconds for stock  85\n",
      "Computing one stock took 77.88152623176575 seconds for stock  86\n",
      "Computing one stock took 72.36755323410034 seconds for stock  87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 68.77231240272522 seconds for stock  88\n",
      "Computing one stock took 70.66145038604736 seconds for stock  89\n",
      "Computing one stock took 70.15222787857056 seconds for stock  90\n",
      "Computing one stock took 73.22786045074463 seconds for stock  93\n",
      "Computing one stock took 78.39202833175659 seconds for stock  94\n",
      "Computing one stock took 74.84231734275818 seconds for stock  95\n",
      "Computing one stock took 73.80405569076538 seconds for stock  96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n",
      "C:\\Users\\laurent\\Documents\\work\\git\\kaggle_volatility\\information_measures.py:798: RuntimeWarning: Zero vectors are within tolerance for emb_dim and emb_dim + 1. Consider raising the tolerance parameter to avoid NaN result.\n",
      "  RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 69.95719146728516 seconds for stock  97\n",
      "Computing one stock took 69.86900925636292 seconds for stock  98\n",
      "Computing one stock took 73.57280087471008 seconds for stock  99\n",
      "Computing one stock took 71.64879179000854 seconds for stock  100\n",
      "Computing one stock took 76.23623132705688 seconds for stock  101\n",
      "Computing one stock took 73.07208061218262 seconds for stock  102\n",
      "Computing one stock took 69.06587648391724 seconds for stock  103\n",
      "Computing one stock took 70.62345790863037 seconds for stock  104\n",
      "Computing one stock took 72.45526337623596 seconds for stock  105\n",
      "Computing one stock took 70.85469627380371 seconds for stock  107\n",
      "Computing one stock took 73.34256720542908 seconds for stock  108\n",
      "Computing one stock took 71.6957654953003 seconds for stock  109\n",
      "Computing one stock took 70.00637483596802 seconds for stock  110\n",
      "Computing one stock took 73.74567747116089 seconds for stock  111\n",
      "Computing one stock took 68.05250597000122 seconds for stock  112\n",
      "Computing one stock took 72.34124779701233 seconds for stock  113\n",
      "Computing one stock took 72.92662787437439 seconds for stock  114\n",
      "Computing one stock took 69.71644568443298 seconds for stock  115\n",
      "Computing one stock took 70.0332179069519 seconds for stock  116\n",
      "Computing one stock took 69.77457427978516 seconds for stock  118\n",
      "Computing one stock took 73.66271471977234 seconds for stock  119\n",
      "Computing one stock took 73.14523005485535 seconds for stock  120\n",
      "Computing one stock took 71.56043553352356 seconds for stock  122\n",
      "Computing one stock took 73.42045783996582 seconds for stock  123\n",
      "Computing one stock took 74.92188334465027 seconds for stock  124\n",
      "Computing one stock took 77.23908829689026 seconds for stock  125\n",
      "Computing one stock took 75.71837019920349 seconds for stock  126\n"
     ]
    }
   ],
   "source": [
    "# Computational time optimized with groupby numba\n",
    "\n",
    "book_all_features = pd.DataFrame()\n",
    "encoder = np.eye(len(all_stocks_ids))\n",
    "\n",
    "list_rv, list_rv2, list_rv3 = [], [], []\n",
    "list_ent, list_fin, list_fin2 = [], [], []\n",
    "list_others, list_others2, list_others3 = [], [], []\n",
    "\n",
    "for stock_id in range(127):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    try:\n",
    "        book_stock = load_book_data_by_id(stock_id,datapath,'train')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Calculate wap for the book\n",
    "    book_stock['wap'] = calc_wap(book_stock)\n",
    "    book_stock['wap2'] = calc_wap2(book_stock)\n",
    "    book_stock['wap3'] = calc_wap3(book_stock)\n",
    "    \n",
    "    # Calculate realized volatility\n",
    "    df_sub = book_stock.groupby('time_id')['wap'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub2 = book_stock.groupby('time_id')['wap2'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index().drop(['time_id'],axis=1)\n",
    "    df_sub3 = book_stock.groupby('time_id')['wap3'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_sub['time_id']]\n",
    "    df_sub = pd.concat([df_sub,df_sub2['wap2'],df_sub3['wap3']],axis=1)\n",
    "    df_sub = df_sub.rename(columns={'time_id':'row_id','wap': 'rv', 'wap2': 'rv2', 'wap3': 'rv3'})\n",
    "    \n",
    "    # Calculate realized volatility last 5 min\n",
    "    df_sub_5 = book_stock.query(f'seconds_in_bucket >= 300').groupby(['time_id'])['wap'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub2_5 = book_stock.query(f'seconds_in_bucket >= 300').groupby(['time_id'])['wap2'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub3_5 = book_stock.query(f'seconds_in_bucket >= 300').groupby(['time_id'])['wap3'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub_5['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_sub_5['time_id']]\n",
    "    df_sub_5 = pd.concat([df_sub_5,df_sub2_5['wap2'],df_sub3_5['wap3']],axis=1)\n",
    "    df_sub_5 = df_sub_5.rename(columns={'time_id':'row_id','wap': 'rv_5', 'wap2': 'rv2_5', 'wap3': 'rv3_5'})\n",
    "    \n",
    "    # Calculate realized volatility last 2 min\n",
    "    df_sub_2 = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id'])['wap'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub2_2 = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id'])['wap2'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()\n",
    "    df_sub3_2 = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id'])['wap3'].agg(calc_rv_from_wap_numba, engine='numba').to_frame().reset_index()    \n",
    "    df_sub_2['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_sub_2['time_id']] \n",
    "    df_sub_2 = pd.concat([df_sub_2,df_sub2_2['wap2'],df_sub3_2['wap3']],axis=1)\n",
    "    df_sub_2 = df_sub_2.rename(columns={'time_id':'row_id','wap': 'rv_2', 'wap2': 'rv2_2', 'wap3': 'rv3_2'})\n",
    "    \n",
    "    list_rv.append(df_sub)\n",
    "    list_rv2.append(df_sub_5)\n",
    "    list_rv3.append(df_sub_2)\n",
    "    \n",
    "    # Calculate other financial metrics from book \n",
    "    df_sub_book_feats = book_stock.groupby(['time_id']).apply(financial_metrics).to_frame().reset_index()\n",
    "    df_sub_book_feats = df_sub_book_feats.rename(columns={0:'embedding'})\n",
    "    df_sub_book_feats[['wap_imbalance','price_spread','bid_spread','ask_spread','total_vol','vol_imbalance']] = pd.DataFrame(df_sub_book_feats.embedding.tolist(), index=df_sub_book_feats.index)\n",
    "    df_sub_book_feats['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_sub_book_feats['time_id']] \n",
    "    df_sub_book_feats = df_sub_book_feats.rename(columns={'time_id':'row_id'}).drop(['embedding'],axis=1)\n",
    "    \n",
    "    df_sub_book_feats5 = book_stock.query(f'seconds_in_bucket >= 300').groupby(['time_id']).apply(financial_metrics).to_frame().reset_index()\n",
    "    df_sub_book_feats5 = df_sub_book_feats5.rename(columns={0:'embedding'})\n",
    "    df_sub_book_feats5[['wap_imbalance5','price_spread5','bid_spread5','ask_spread5','total_vol5','vol_imbalance5']] = pd.DataFrame(df_sub_book_feats5.embedding.tolist(), index=df_sub_book_feats5.index)\n",
    "    df_sub_book_feats5['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_sub_book_feats5['time_id']] \n",
    "    df_sub_book_feats5 = df_sub_book_feats5.rename(columns={'time_id':'row_id'}).drop(['embedding'],axis=1)\n",
    "    \n",
    "    list_fin.append(df_sub_book_feats)\n",
    "    list_fin2.append(df_sub_book_feats5)\n",
    "    \n",
    "    # Compute entropy \n",
    "    df_ent = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id']).apply(entropy_from_df).to_frame().reset_index().fillna(0)\n",
    "    df_ent2 = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id']).apply(entropy_from_df2).to_frame().reset_index().fillna(0)\n",
    "    df_ent3 = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id']).apply(entropy_from_df3).to_frame().reset_index().fillna(0)\n",
    "    df_ent['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_ent['time_id']]\n",
    "    df_ent = df_ent.rename(columns={'time_id':'row_id',0:'entropy'})\n",
    "    df_ent2 = df_ent2.rename(columns={0:'entropy2'}).drop(['time_id'],axis=1)\n",
    "    df_ent3 = df_ent3.rename(columns={0:'entropy3'}).drop(['time_id'],axis=1)\n",
    "    df_ent = pd.concat([df_ent,df_ent2,df_ent3],axis=1)\n",
    "    list_ent.append(df_ent)\n",
    "    \n",
    "    # Compute other metrics\n",
    "    df_others = book_stock.groupby(['time_id']).apply(other_metrics).to_frame().reset_index().fillna(0)\n",
    "    df_others = df_others.rename(columns={0:'embedding'})\n",
    "    df_others[['linearFit1_1','linearFit1_2','linearFit1_3','wap_std1_1','wap_std1_2','wap_std1_3']] = pd.DataFrame(df_others.embedding.tolist(), index=df_others.index)\n",
    "    df_others['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_others['time_id']] \n",
    "    df_others = df_others.rename(columns={'time_id':'row_id'}).drop(['embedding'],axis=1)\n",
    "    list_others.append(df_others)\n",
    "    \n",
    "    df_others2 = book_stock.query(f'seconds_in_bucket >= 300').groupby(['time_id']).apply(other_metrics).to_frame().reset_index().fillna(0)\n",
    "    df_others2 = df_others2.rename(columns={0:'embedding'})\n",
    "    df_others2[['linearFit2_1','linearFit2_2','linearFit2_3','wap_std2_1','wap_std2_2','wap_std2_3']] = pd.DataFrame(df_others2.embedding.tolist(), index=df_others2.index)\n",
    "    df_others2['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_others2['time_id']] \n",
    "    df_others2 = df_others2.rename(columns={'time_id':'row_id'}).drop(['embedding'],axis=1)\n",
    "    list_others2.append(df_others2)\n",
    "    \n",
    "    df_others3 = book_stock.query(f'seconds_in_bucket >= 480').groupby(['time_id']).apply(other_metrics).to_frame().reset_index().fillna(0)\n",
    "    df_others3 = df_others3.rename(columns={0:'embedding'})\n",
    "    df_others3[['linearFit3_1','linearFit3_2','linearFit3_3','wap_std3_1','wap_std3_2','wap_std3_3']] = pd.DataFrame(df_others3.embedding.tolist(), index=df_others3.index)\n",
    "    df_others3['time_id'] = [f'{stock_id}-{time_id}' for time_id in df_others3['time_id']] \n",
    "    df_others3 = df_others3.rename(columns={'time_id':'row_id'}).drop(['embedding'],axis=1)\n",
    "    list_others3.append(df_others3)\n",
    "    \n",
    "    print('Computing one stock took', time.time() - start, 'seconds for stock ', stock_id)\n",
    "    \n",
    "# Create features dataframe\n",
    "df_submission = pd.concat(list_rv)\n",
    "df_submission2 = pd.concat(list_rv2)\n",
    "df_submission3 = pd.concat(list_rv3)\n",
    "df_ent_concat = pd.concat(list_ent)\n",
    "df_fin_concat = pd.concat(list_fin)\n",
    "df_fin2_concat = pd.concat(list_fin2)\n",
    "df_others = pd.concat(list_others)\n",
    "df_others2 = pd.concat(list_others2)\n",
    "df_others3 = pd.concat(list_others3)\n",
    "\n",
    "df_book_features = df_submission.merge(df_submission2, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_submission3, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_ent_concat, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_fin_concat, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_fin2_concat, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_others, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_others2, on = ['row_id'], how='left').fillna(0)\n",
    "df_book_features = df_book_features.merge(df_others3, on = ['row_id'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_book_features.to_csv('book_features_tot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add encoded stock\n",
    "encoder = np.eye(len(all_stocks_ids))\n",
    "encoded = list()\n",
    "\n",
    "for i in range(df_book_features.shape[0]):\n",
    "    stock_id = int(df_book_features['row_id'][i].split('-')[0])\n",
    "    encoded_stock = encoder[np.where(all_stocks_ids == int(stock_id))[0],:]\n",
    "    encoded.append(encoded_stock)\n",
    "\n",
    "encoded_pd = pd.DataFrame(np.array(encoded).reshape(df_book_features.shape[0],np.array(all_stocks_ids).shape[0]))\n",
    "df_book_features_encoded = pd.concat([df_book_features, encoded_pd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock id computing = 0\n",
      "Computing one stock entropy took 31.55561923980713 seconds for stock  0\n",
      "stock id computing = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dc044da39d32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mstocks_id_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mrow_id_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{stock_id}-{time_id}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mvolatility_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrealized_volatility_from_book_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;31m#entropy2_list.append(entropy_from_book(book_stock_time=book_stock_time,last_min=2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mlinearFit_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mrealized_volatility_from_book_pd\u001b[1;34m(book_stock_time)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mwap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_wap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mreturns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mvolatility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrealized_volatility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvolatility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mrealized_volatility\u001b[1;34m(series_log_return)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrealized_volatility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_log_return\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_log_return\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_wap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_pd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2242\u001b[1;33m                           initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11423\u001b[0m             \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11424\u001b[0m             \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11425\u001b[1;33m             \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11426\u001b[0m         )\n\u001b[0;32m  11427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4234\u001b[0m                 )\n\u001b[0;32m   4235\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4236\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_reindex_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnansum\u001b[1;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m    501\u001b[0m     values, mask, dtype, dtype_max, _ = _get_values(\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     \u001b[0mdtype_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype_max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_get_values\u001b[1;34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_ok\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;31m# promote if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mputmask\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "book_all_features = pd.DataFrame()\n",
    "encoder = np.eye(len(all_stocks_ids))\n",
    "\n",
    "stocks_id_list, row_id_list = [], []\n",
    "volatility_list, entropy2_list = [], []\n",
    "linearFit_list, linearFit5_list, linearFit2_list = [], [], []\n",
    "wap_std_list, wap_std5_list, wap_std2_list = [], [], []\n",
    "\n",
    "for file in book_path_train:\n",
    "    start = time.time()\n",
    "    \n",
    "    book_stock = pd.read_parquet(file)\n",
    "    stock_id = file.split('=')[1]\n",
    "    print('stock id computing = ' + str(stock_id))\n",
    "    stock_time_ids = book_stock['time_id'].unique()\n",
    "    for time_id in stock_time_ids:     \n",
    "        \n",
    "        # Access book data at this time + stock\n",
    "        book_stock_time = book_stock[book_stock['time_id'] == time_id]\n",
    "\n",
    "        # Create feature matrix\n",
    "        stocks_id_list.append(stock_id)\n",
    "        row_id_list.append(str(f'{stock_id}-{time_id}'))\n",
    "        volatility_list.append(realized_volatility_from_book_pd(book_stock_time=book_stock_time))\n",
    "        entropy2_list.append(entropy_from_book(book_stock_time=book_stock_time,last_min=2))\n",
    "        linearFit_list.append(linearFit(book_stock_time=book_stock_time,last_min=10))\n",
    "        linearFit5_list.append(linearFit(book_stock_time=book_stock_time,last_min=5))\n",
    "        linearFit2_list.append(linearFit(book_stock_time=book_stock_time,last_min=2))\n",
    "        wap_std_list.append(wapStat(book_stock_time=book_stock_time,last_min=10))\n",
    "        wap_std5_list.append(wapStat(book_stock_time=book_stock_time,last_min=5))\n",
    "        wap_std2_list.append(wapStat(book_stock_time=book_stock_time,last_min=2))\n",
    "        \n",
    "    print('Computing one stock entropy took', time.time() - start, 'seconds for stock ', stock_id)\n",
    "\n",
    "# Merge targets\n",
    "stocks_id_pd = pd.DataFrame(stocks_id_list,columns=['stock_id'])\n",
    "row_id_pd = pd.DataFrame(row_id_list,columns=['row_id'])\n",
    "volatility_pd = pd.DataFrame(volatility_list,columns=['volatility'])\n",
    "entropy2_pd = pd.DataFrame(entropy2_list,columns=['entropy2'])\n",
    "linearFit_pd = pd.DataFrame(linearFit_list,columns=['linearFit_coef'])\n",
    "linearFit5_pd = pd.DataFrame(linearFit5_list,columns=['linearFit_coef5'])\n",
    "linearFit2_pd = pd.DataFrame(linearFit2_list,columns=['linearFit_coef2'])\n",
    "wap_std_pd = pd.DataFrame(wap_std_list,columns=['wap_std'])\n",
    "wap_std5_pd = pd.DataFrame(wap_std5_list,columns=['wap_std5'])\n",
    "wap_std2_pd = pd.DataFrame(wap_std2_list,columns=['wap_std2'])\n",
    "\n",
    "book_all_features = pd.concat([stocks_id_pd,row_id_pd,volatility_pd,entropy2_pd,linearFit_pd,linearFit5_pd,linearFit2_pd,\n",
    "                              wap_std_pd,wap_std5_pd,wap_std2_pd],axis=1)\n",
    "\n",
    "book_all_features = train.merge(book_all_features, on = ['row_id'])\n",
    "\n",
    "# Add encoded stock\n",
    "encoded = list()\n",
    "\n",
    "for i in range(book_all_features.shape[0]):\n",
    "    stock_id = book_all_features['stock_id'][i]\n",
    "    encoded_stock = encoder[np.where(all_stocks_ids == int(stock_id))[0],:]\n",
    "    encoded.append(encoded_stock)\n",
    "\n",
    "encoded_pd = pd.DataFrame(np.array(encoded).reshape(book_all_features.shape[0],np.array(all_stocks_ids).shape[0]))\n",
    "book_all_features_encoded = pd.concat([book_all_features, encoded_pd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>volatility</th>\n",
       "      <th>entropy2</th>\n",
       "      <th>linearFit_coef</th>\n",
       "      <th>linearFit_coef5</th>\n",
       "      <th>linearFit_coef2</th>\n",
       "      <th>wap_std</th>\n",
       "      <th>wap_std5</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.357092</td>\n",
       "      <td>3.874554e-06</td>\n",
       "      <td>-7.296451e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.173592</td>\n",
       "      <td>6.045011e-07</td>\n",
       "      <td>2.164258e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>-3.463848e-06</td>\n",
       "      <td>-8.714889e-06</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.076961</td>\n",
       "      <td>-4.829273e-06</td>\n",
       "      <td>-4.213925e-06</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>-3.157112e-09</td>\n",
       "      <td>2.151035e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126-32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.264883</td>\n",
       "      <td>-8.803732e-07</td>\n",
       "      <td>1.123249e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126-32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.218649</td>\n",
       "      <td>7.455736e-06</td>\n",
       "      <td>1.272477e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126-32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.244481</td>\n",
       "      <td>2.550217e-06</td>\n",
       "      <td>7.278551e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126-32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.423108</td>\n",
       "      <td>4.275249e-07</td>\n",
       "      <td>-5.802447e-06</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126-32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.095729</td>\n",
       "      <td>-1.223051e-06</td>\n",
       "      <td>-1.403475e-06</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id    target stock_id  volatility  entropy2  linearFit_coef  \\\n",
       "0             0-5  0.004136        0    0.004499  0.357092    3.874554e-06   \n",
       "1            0-11  0.001445        0    0.001204  0.173592    6.045011e-07   \n",
       "2            0-16  0.002168        0    0.002369  0.066508   -3.463848e-06   \n",
       "3            0-31  0.002195        0    0.002574  0.076961   -4.829273e-06   \n",
       "4            0-62  0.001747        0    0.001894  0.164630   -3.157112e-09   \n",
       "...           ...       ...      ...         ...       ...             ...   \n",
       "428927  126-32751  0.003461      126    0.003691  0.264883   -8.803732e-07   \n",
       "428928  126-32753  0.003113      126    0.004104  0.218649    7.455736e-06   \n",
       "428929  126-32758  0.004070      126    0.003118  0.244481    2.550217e-06   \n",
       "428930  126-32763  0.003357      126    0.003661  0.423108    4.275249e-07   \n",
       "428931  126-32767  0.002090      126    0.002091  0.095729   -1.223051e-06   \n",
       "\n",
       "        linearFit_coef5  linearFit_coef2   wap_std  wap_std5  ...  102  103  \\\n",
       "0         -7.296451e-07        -0.000002  0.000698  0.000498  ...  0.0  0.0   \n",
       "1          2.164258e-07         0.000001  0.000258  0.000186  ...  0.0  0.0   \n",
       "2         -8.714889e-06        -0.000008  0.000924  0.000911  ...  0.0  0.0   \n",
       "3         -4.213925e-06        -0.000007  0.000791  0.000401  ...  0.0  0.0   \n",
       "4          2.151035e-06         0.000006  0.000265  0.000184  ...  0.0  0.0   \n",
       "...                 ...              ...       ...       ...  ...  ...  ...   \n",
       "428927     1.123249e-06         0.000005  0.000473  0.000302  ...  0.0  0.0   \n",
       "428928     1.272477e-05         0.000024  0.001142  0.000777  ...  0.0  0.0   \n",
       "428929     7.278551e-06         0.000011  0.000503  0.000443  ...  0.0  0.0   \n",
       "428930    -5.802447e-06        -0.000010  0.000466  0.000477  ...  0.0  0.0   \n",
       "428931    -1.403475e-06        -0.000008  0.000346  0.000442  ...  0.0  0.0   \n",
       "\n",
       "        104  105  106  107  108  109  110  111  \n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "428927  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "428928  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "428929  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "428930  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "428931  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[428932 rows x 123 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_all_features_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence model perf : 0.34135449018801606\n",
      "[21:08:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "New model xgb perf :  0.306084377117114\n",
      "New model lgbm perf :  0.2927659975146637\n",
      "New model catboost perf :  0.28643356812572324\n",
      "New model mean gradient boosted trees :  0.2931403264914029\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "X = book_all_features_encoded.drop(['row_id','target','stock_id'],axis=1)\n",
    "y = book_all_features_encoded['target']\n",
    "\n",
    "\n",
    "print('Persistence model perf :', rmspe(y,book_all_features_encoded['volatility']))\n",
    "\n",
    "xgboost_default = xgb.XGBRegressor(random_state=0)\n",
    "xgboost_default.fit(X,y)\n",
    "\n",
    "yhat_xgb = xgboost_default.predict(X)\n",
    "print('New model xgb perf : ', rmspe(y, yhat_xgb))\n",
    "\n",
    "lightgbm_default = LGBMRegressor()\n",
    "lightgbm_default.fit(X,y)\n",
    "yhat_light = lightgbm_default.predict(X)\n",
    "print('New model lgbm perf : ', rmspe(y, yhat_light))\n",
    "\n",
    "catboost_default = CatBoostRegressor(verbose=0)\n",
    "catboost_default.fit(X,y)\n",
    "yhat_cat = catboost_default.predict(X)\n",
    "print('New model catboost perf : ', rmspe(y, yhat_cat))\n",
    "\n",
    "print('New model mean gradient boosted trees : ', rmspe(y,(yhat_xgb + yhat_light + yhat_cat)/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>rv</th>\n",
       "      <th>rv2</th>\n",
       "      <th>rv3</th>\n",
       "      <th>rv_5</th>\n",
       "      <th>rv2_5</th>\n",
       "      <th>rv3_5</th>\n",
       "      <th>rv_2</th>\n",
       "      <th>rv2_2</th>\n",
       "      <th>rv3_2</th>\n",
       "      <th>...</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126-32751</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126-32753</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126-32758</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126-32763</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126-32767</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id        rv       rv2       rv3      rv_5     rv2_5     rv3_5  \\\n",
       "0             0-5  0.004499  0.006999  0.006119  0.002929  0.004861  0.004492   \n",
       "1            0-11  0.001204  0.002476  0.002320  0.000980  0.001999  0.001600   \n",
       "2            0-16  0.002330  0.004787  0.004684  0.001293  0.003195  0.002354   \n",
       "3            0-31  0.002574  0.003637  0.002881  0.001776  0.002713  0.001814   \n",
       "4            0-62  0.001880  0.003254  0.003164  0.001518  0.002105  0.002344   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "428927  126-32751  0.003691  0.005876  0.006107  0.002899  0.003776  0.004230   \n",
       "428928  126-32753  0.004104  0.004991  0.004879  0.003422  0.003392  0.003256   \n",
       "428929  126-32758  0.003118  0.006019  0.005305  0.002787  0.005387  0.004479   \n",
       "428930  126-32763  0.003661  0.005362  0.005186  0.002378  0.003156  0.003025   \n",
       "428931  126-32767  0.002091  0.003010  0.003277  0.001414  0.002425  0.002444   \n",
       "\n",
       "            rv_2     rv2_2     rv3_2  ...  102  103  104  105  106  107  108  \\\n",
       "0       0.001460  0.003019  0.002928  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1       0.000857  0.001777  0.001355  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       0.000668  0.002516  0.001668  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3       0.000942  0.001351  0.000377  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4       0.001154  0.000797  0.001381  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...          ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "428927  0.001557  0.001777  0.002148  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "428928  0.002529  0.002465  0.002324  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "428929  0.001166  0.002926  0.003021  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "428930  0.001035  0.001602  0.001675  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "428931  0.000744  0.001122  0.001277  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        109  110  111  \n",
       "0       0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  \n",
       "...     ...  ...  ...  \n",
       "428927  0.0  0.0  1.0  \n",
       "428928  0.0  0.0  1.0  \n",
       "428929  0.0  0.0  1.0  \n",
       "428930  0.0  0.0  1.0  \n",
       "428931  0.0  0.0  1.0  \n",
       "\n",
       "[428932 rows x 155 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_book_features_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence model perf : 0.3396985576673107\n",
      "[07:34:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "New model xgb perf :  0.296904151446481\n",
      "New model lgbm perf :  0.2851266471230485\n",
      "New model catboost perf :  0.2775810141798436\n",
      "New model mean gradient boosted trees :  0.2843762726709955\n"
     ]
    }
   ],
   "source": [
    "# df_book_features_encoded \n",
    "\n",
    "X = df_book_features_encoded.drop(['row_id'],axis=1)\n",
    "y = train['target']\n",
    "\n",
    "\n",
    "print('Persistence model perf :', rmspe(y,df_book_features_encoded['rv']))\n",
    "\n",
    "xgboost_default = xgb.XGBRegressor(random_state=0)\n",
    "xgboost_default.fit(X,y)\n",
    "\n",
    "yhat_xgb = xgboost_default.predict(X)\n",
    "print('New model xgb perf : ', rmspe(y, yhat_xgb))\n",
    "\n",
    "lightgbm_default = LGBMRegressor()\n",
    "lightgbm_default.fit(X,y)\n",
    "yhat_light = lightgbm_default.predict(X)\n",
    "print('New model lgbm perf : ', rmspe(y, yhat_light))\n",
    "\n",
    "catboost_default = CatBoostRegressor(verbose=0)\n",
    "catboost_default.fit(X,y)\n",
    "yhat_cat = catboost_default.predict(X)\n",
    "print('New model catboost perf : ', rmspe(y, yhat_cat))\n",
    "\n",
    "print('New model mean gradient boosted trees : ', rmspe(y,(yhat_xgb + yhat_light + yhat_cat)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126-32751</td>\n",
       "      <td>0.003823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126-32753</td>\n",
       "      <td>0.004055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126-32758</td>\n",
       "      <td>0.003705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126-32763</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126-32767</td>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id    target\n",
       "0             0-5  0.004207\n",
       "1            0-11  0.001555\n",
       "2            0-16  0.002867\n",
       "3            0-31  0.002766\n",
       "4            0-62  0.001988\n",
       "...           ...       ...\n",
       "428927  126-32751  0.003823\n",
       "428928  126-32753  0.004055\n",
       "428929  126-32758  0.003705\n",
       "428930  126-32763  0.003727\n",
       "428931  126-32767  0.002498\n",
       "\n",
       "[428932 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_pd = pd.DataFrame(yhat_cat,columns=['target'])\n",
    "submission_file = pd.concat([df_book_features['row_id'],yhat_pd],axis=1)\n",
    "submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10934\n",
      "[LightGBM] [Info] Number of data points in the train set: 428932, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score 0.003880\n",
      "[1]\ttraining's rmse: 0.00291376\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's rmse: 0.00289171\n",
      "[3]\ttraining's rmse: 0.00286982\n",
      "[4]\ttraining's rmse: 0.00284822\n",
      "[5]\ttraining's rmse: 0.00282697\n",
      "[6]\ttraining's rmse: 0.00280587\n",
      "[7]\ttraining's rmse: 0.00278512\n",
      "[8]\ttraining's rmse: 0.00276454\n",
      "[9]\ttraining's rmse: 0.00274428\n",
      "[10]\ttraining's rmse: 0.00272428\n",
      "[11]\ttraining's rmse: 0.00270451\n",
      "[12]\ttraining's rmse: 0.00268488\n",
      "[13]\ttraining's rmse: 0.00266561\n",
      "[14]\ttraining's rmse: 0.00264648\n",
      "[15]\ttraining's rmse: 0.00262755\n",
      "[16]\ttraining's rmse: 0.00260885\n",
      "[17]\ttraining's rmse: 0.00259039\n",
      "[18]\ttraining's rmse: 0.00257219\n",
      "[19]\ttraining's rmse: 0.00255419\n",
      "[20]\ttraining's rmse: 0.00253641\n",
      "[21]\ttraining's rmse: 0.00251885\n",
      "[22]\ttraining's rmse: 0.0025015\n",
      "[23]\ttraining's rmse: 0.00248436\n",
      "[24]\ttraining's rmse: 0.00246744\n",
      "[25]\ttraining's rmse: 0.00245073\n",
      "[26]\ttraining's rmse: 0.00243431\n",
      "[27]\ttraining's rmse: 0.00241802\n",
      "[28]\ttraining's rmse: 0.00240187\n",
      "[29]\ttraining's rmse: 0.002386\n",
      "[30]\ttraining's rmse: 0.00237033\n",
      "[31]\ttraining's rmse: 0.00235502\n",
      "[32]\ttraining's rmse: 0.00233968\n",
      "[33]\ttraining's rmse: 0.00232458\n",
      "[34]\ttraining's rmse: 0.00230962\n",
      "[35]\ttraining's rmse: 0.00229496\n",
      "[36]\ttraining's rmse: 0.00228043\n",
      "[37]\ttraining's rmse: 0.00226602\n",
      "[38]\ttraining's rmse: 0.00225194\n",
      "[39]\ttraining's rmse: 0.00223806\n",
      "[40]\ttraining's rmse: 0.00222429\n",
      "[41]\ttraining's rmse: 0.00221064\n",
      "[42]\ttraining's rmse: 0.00219713\n",
      "[43]\ttraining's rmse: 0.0021839\n",
      "[44]\ttraining's rmse: 0.00217074\n",
      "[45]\ttraining's rmse: 0.00215784\n",
      "[46]\ttraining's rmse: 0.00214515\n",
      "[47]\ttraining's rmse: 0.0021326\n",
      "[48]\ttraining's rmse: 0.00212012\n",
      "[49]\ttraining's rmse: 0.00210785\n",
      "[50]\ttraining's rmse: 0.00209582\n",
      "[51]\ttraining's rmse: 0.00208393\n",
      "[52]\ttraining's rmse: 0.00207212\n",
      "[53]\ttraining's rmse: 0.00206045\n",
      "[54]\ttraining's rmse: 0.00204901\n",
      "[55]\ttraining's rmse: 0.00203774\n",
      "[56]\ttraining's rmse: 0.00202652\n",
      "[57]\ttraining's rmse: 0.00201546\n",
      "[58]\ttraining's rmse: 0.00200464\n",
      "[59]\ttraining's rmse: 0.00199392\n",
      "[60]\ttraining's rmse: 0.0019834\n",
      "[61]\ttraining's rmse: 0.00197301\n",
      "[62]\ttraining's rmse: 0.00196268\n",
      "[63]\ttraining's rmse: 0.0019525\n",
      "[64]\ttraining's rmse: 0.00194254\n",
      "[65]\ttraining's rmse: 0.0019327\n",
      "[66]\ttraining's rmse: 0.00192296\n",
      "[67]\ttraining's rmse: 0.00191335\n",
      "[68]\ttraining's rmse: 0.00190385\n",
      "[69]\ttraining's rmse: 0.00189453\n",
      "[70]\ttraining's rmse: 0.00188529\n",
      "[71]\ttraining's rmse: 0.00187626\n",
      "[72]\ttraining's rmse: 0.00186728\n",
      "[73]\ttraining's rmse: 0.00185848\n",
      "[74]\ttraining's rmse: 0.00184984\n",
      "[75]\ttraining's rmse: 0.00184124\n",
      "[76]\ttraining's rmse: 0.00183282\n",
      "[77]\ttraining's rmse: 0.00182457\n",
      "[78]\ttraining's rmse: 0.00181632\n",
      "[79]\ttraining's rmse: 0.00180822\n",
      "[80]\ttraining's rmse: 0.00180026\n",
      "[81]\ttraining's rmse: 0.00179237\n",
      "[82]\ttraining's rmse: 0.00178462\n",
      "[83]\ttraining's rmse: 0.00177703\n",
      "[84]\ttraining's rmse: 0.00176955\n",
      "[85]\ttraining's rmse: 0.00176211\n",
      "[86]\ttraining's rmse: 0.00175479\n",
      "[87]\ttraining's rmse: 0.00174763\n",
      "[88]\ttraining's rmse: 0.00174055\n",
      "[89]\ttraining's rmse: 0.00173354\n",
      "[90]\ttraining's rmse: 0.00172669\n",
      "[91]\ttraining's rmse: 0.00171986\n",
      "[92]\ttraining's rmse: 0.00171322\n",
      "[93]\ttraining's rmse: 0.00170663\n",
      "[94]\ttraining's rmse: 0.0017001\n",
      "[95]\ttraining's rmse: 0.00169373\n",
      "[96]\ttraining's rmse: 0.00168743\n",
      "[97]\ttraining's rmse: 0.00168127\n",
      "[98]\ttraining's rmse: 0.00167516\n",
      "[99]\ttraining's rmse: 0.00166917\n",
      "[100]\ttraining's rmse: 0.00166328\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.00166328\n",
      "New model lgbm perf :  0.5511517699840043\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "lgbm_params = {\n",
    "    'objective': 'rmse', \n",
    "    'metric': 'rmse', \n",
    "    'boosting': 'gbdt',\n",
    "    'early_stopping_rounds': 30,\n",
    "    'learning_rate': 0.01,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8}\n",
    "\n",
    "lgbm_train = lgbm.Dataset(X,y)\n",
    "model = lgbm.train(params=lgbm_params,train_set=lgbm_train, valid_sets=lgbm_train)\n",
    "yhat_light_bis = model.predict(X)\n",
    "print('New model lgbm perf : ', rmspe(y, yhat_light_bis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main evaluation code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock id computing = 0\n",
      "Computing one stock entropy took 0.03986024856567383 seconds for stock  0\n",
      "  row_id stock_id  volatility  entropy2  linearFit_coef  linearFit_coef5  \\\n",
      "0    0-4        0    0.000294         0        0.000059                0   \n",
      "\n",
      "   linearFit_coef2   wap_std  wap_std5  wap_std2  ...  102  103  104  105  \\\n",
      "0                0  0.000118         0         0  ...  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   106  107  108  109  110  111  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[1 rows x 122 columns]\n",
      "stock id computing = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ff6ffd2686d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                  \u001b[0mtrade_path_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist_trade_file_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                  \u001b[0mall_stocks_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_stocks_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                  test_file=test)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-155bf651e8be>\u001b[0m in \u001b[0;36mprediction_function\u001b[1;34m(pred, book_path_train, trade_path_train, targets, book_path_test, trade_path_test, all_stocks_ids, test_file)\u001b[0m\n\u001b[0;32m     37\u001b[0m                                             \u001b[0mbook_path_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_path_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                                             \u001b[0mall_stocks_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_stocks_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                                             test_file=test_file)\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mentropy_Prediction\u001b[1;34m(book_path_train, prediction_column_name, train_targets_pd, book_path_test, all_stocks_ids, test_file)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_features_encoded_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[0mbook_features_encoded_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeFeatures_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_path_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_targets_pd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_stocks_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook_features_encoded_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'row_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stock_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mcomputeFeatures_1\u001b[1;34m(book_path, prediction_column_name, train_targets_pd, all_stocks_ids)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[0mlinearFit_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mlinearFit5_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mlinearFit2_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mwap_std_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwapStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mwap_std5_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwapStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mlinearFit\u001b[1;34m(book_stock_time, last_min)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mwap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_wap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_stock_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[0mt_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbook_stock_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'seconds_in_bucket'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\work\\git\\kaggle_volatility\\support_file.py\u001b[0m in \u001b[0;36mcompute_wap\u001b[1;34m(book_pd)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_wap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_pd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mwap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbook_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bid_price1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbook_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ask_size1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbook_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ask_price1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbook_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bid_size1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbook_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bid_size1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mbook_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ask_size1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2876\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m         \u001b[1;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   3536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3537\u001b[0m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3538\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3539\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miget\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \"\"\"\n\u001b[1;32m--> 988\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Glob book file train (contains all paths for each file in this folder)\n",
    "list_order_book_file_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "list_order_book_file_test = glob.glob(os.path.join(datapath,'book_test.parquet','*'))\n",
    "list_trade_file_train = glob.glob(os.path.join(datapath,'trade_train.parquet','*')) \n",
    "list_trade_file_test = glob.glob(os.path.join(datapath,'trade_test.parquet','*'))\n",
    "\n",
    "# Compute predictions\n",
    "predictions = prediction_function(pred='entropy',\n",
    "                                 book_path_train=list_order_book_file_train,\n",
    "                                 trade_path_train=list_trade_file_train,\n",
    "                                 targets=train,\n",
    "                                 book_path_test=list_order_book_file_test,\n",
    "                                 trade_path_test=list_trade_file_test,\n",
    "                                 all_stocks_ids=all_stocks_ids,\n",
    "                                 test_file=test)\n",
    "\n",
    "predictions.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
