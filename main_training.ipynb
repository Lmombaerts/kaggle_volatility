{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code for Kaggle - Optiver Realized Volatility Prediction\n",
    "@LaurentMombaerts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE TO SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "machine = 'local'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lib Import / Data loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Maths\n",
    "from scipy.interpolate import interp1d\n",
    "from arch import arch_model\n",
    "\n",
    "# Paths tricks\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Support code\n",
    "from support_file import *\n",
    "#from support_file_extension import *\n",
    "from information_measures import *\n",
    "\n",
    "if machine == 'local':\n",
    "    datapath = os.path.join(str(Path.home()), 'ownCloud', 'Data', 'Kaggle', 'optiver-realized-volatility-prediction')\n",
    "\n",
    "    # Load dataset\n",
    "    train = pd.read_csv(os.path.join(datapath,'train.csv')) \n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    # Load test ids\n",
    "    test = pd.read_csv(os.path.join(datapath,'test.csv'))\n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "elif machine == 'kaggle':\n",
    "    \n",
    "    # Load dataset\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    all_stocks_ids = train['stock_id'].unique()\n",
    "    all_time_ids = train['time_id'].unique()\n",
    "\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    train = train[['row_id','target']]\n",
    "\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv') \n",
    "    test = test.drop(['stock_id','time_id'],axis=1)\n",
    "    \n",
    "    datapath = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition metric\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "# Prediction function (chose here which prediction strategy to use)\n",
    "def prediction_function(pred, machine, targets, all_stocks_ids, datapath):\n",
    "        \n",
    "    if pred == 'entropy':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_train['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_wEntropy(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_wEntropy(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent_withoutEncoding':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent_noCode(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "    if pred == 'new_test_laurent_withoutEncoding_wTrades':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_newTest_Laurent_wTrades(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "        \n",
    "    if pred == 'garch':\n",
    "        \n",
    "        if machine == 'local':\n",
    "            book_path_train = glob.glob(os.path.join(datapath,'book_train.parquet','*')) \n",
    "            \n",
    "            # fit garch and predict\n",
    "            prediction = garch_volatility_per_stock(list_file=book_path_train, prediction_column_name='pred')\n",
    "            \n",
    "            # Merge and evaluate results\n",
    "            prediction = train.merge(prediction[['row_id','pred']], on = ['row_id'], how = 'left')\n",
    "            prediction = prediction[prediction.pred.notnull()]\n",
    "\n",
    "            # Estimate performances\n",
    "            R2 = round(r2_score(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "            RMSPE = round(rmspe(y_true = prediction['target'], y_pred = prediction['pred']),3)\n",
    "\n",
    "            print('--')\n",
    "            print(f'Performance of prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n",
    "\n",
    "            prediction = prediction.drop(columns=['target'])\n",
    "            prediction = prediction.rename(columns={'pred': 'target'})\n",
    "            \n",
    "            return prediction\n",
    "        \n",
    "    if pred == 'new_version':\n",
    "        if machine == 'local':\n",
    "            # Load data\n",
    "            df_features_encoded_test = computeFeatures_july(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            df_features_encoded_train = computeFeatures_july(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "            X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "            y = targets\n",
    "            \n",
    "            # Model\n",
    "            model = CatBoostRegressor(verbose=0)\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Predicting targets from same\n",
    "            yhat = model.predict(X)\n",
    "            \n",
    "            print('New model catboost perf : ', rmspe(y, yhat))\n",
    "            \n",
    "            # Submission file\n",
    "            yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "            return pd.concat([df_features_encoded_train['row_id'],yhat_pd],axis=1)\n",
    "\n",
    "        # Features computation\n",
    "        df_features_encoded_test = computeFeatures_july(machine=machine, dataset='test', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        df_features_encoded_train = computeFeatures_july(machine=machine, dataset='train', all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "        \n",
    "        # Training model\n",
    "        X = df_features_encoded_train.drop(['row_id'],axis=1)\n",
    "        y = targets\n",
    "        \n",
    "        # Optimized model\n",
    "        model = CatBoostRegressor(verbose=0)\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        # Predicting targets from test\n",
    "        X_test = df_features_encoded_test.drop(['row_id'],axis=1)\n",
    "        yhat = model.predict(X_test)\n",
    "        \n",
    "        # Submission file\n",
    "        yhat_pd = pd.DataFrame(yhat,columns=['target'])\n",
    "        submission_file = pd.concat([df_features_encoded_test['row_id'],yhat_pd],axis=1)\n",
    "        \n",
    "\n",
    "    return submission_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 1.286210060119629 seconds for stock  0\n",
      "Computing one stock took 17.27484154701233 seconds for stock  0\n",
      "Computing one stock took 18.96580171585083 seconds for stock  1\n",
      "Computing one stock took 18.549424409866333 seconds for stock  2\n",
      "Computing one stock took 17.85348892211914 seconds for stock  3\n",
      "Computing one stock took 18.157620668411255 seconds for stock  4\n",
      "Computing one stock took 17.975078344345093 seconds for stock  5\n",
      "Computing one stock took 18.700467586517334 seconds for stock  6\n",
      "Computing one stock took 18.16360116004944 seconds for stock  7\n",
      "Computing one stock took 20.635711908340454 seconds for stock  8\n",
      "Computing one stock took 18.465434312820435 seconds for stock  9\n",
      "Computing one stock took 19.375681161880493 seconds for stock  10\n",
      "Computing one stock took 18.845505475997925 seconds for stock  11\n",
      "Computing one stock took 23.808120727539062 seconds for stock  13\n",
      "Computing one stock took 24.409007787704468 seconds for stock  14\n",
      "Computing one stock took 21.781853675842285 seconds for stock  15\n",
      "Computing one stock took 20.307770490646362 seconds for stock  16\n",
      "Computing one stock took 20.409886837005615 seconds for stock  17\n",
      "Computing one stock took 19.351500272750854 seconds for stock  18\n",
      "Computing one stock took 20.01668119430542 seconds for stock  19\n",
      "Computing one stock took 21.90666937828064 seconds for stock  20\n",
      "Computing one stock took 24.67710041999817 seconds for stock  21\n",
      "Computing one stock took 21.61386513710022 seconds for stock  22\n",
      "Computing one stock took 21.458340644836426 seconds for stock  23\n",
      "Computing one stock took 23.314212560653687 seconds for stock  26\n",
      "Computing one stock took 20.801267623901367 seconds for stock  27\n",
      "Computing one stock took 22.571200847625732 seconds for stock  28\n",
      "Computing one stock took 24.077975511550903 seconds for stock  29\n",
      "Computing one stock took 22.25674033164978 seconds for stock  30\n",
      "Computing one stock took 23.00257396697998 seconds for stock  31\n",
      "Computing one stock took 24.739539623260498 seconds for stock  32\n",
      "Computing one stock took 22.65636157989502 seconds for stock  33\n",
      "Computing one stock took 23.570201873779297 seconds for stock  34\n",
      "Computing one stock took 24.47832989692688 seconds for stock  35\n",
      "Computing one stock took 24.235880136489868 seconds for stock  36\n",
      "Computing one stock took 22.6388521194458 seconds for stock  37\n",
      "Computing one stock took 23.332269430160522 seconds for stock  38\n",
      "Computing one stock took 24.01272201538086 seconds for stock  39\n",
      "Computing one stock took 23.20577383041382 seconds for stock  40\n",
      "Computing one stock took 24.683796405792236 seconds for stock  41\n",
      "Computing one stock took 24.014322996139526 seconds for stock  42\n",
      "Computing one stock took 24.781413555145264 seconds for stock  43\n",
      "Computing one stock took 24.653146743774414 seconds for stock  44\n",
      "Computing one stock took 24.626659870147705 seconds for stock  46\n",
      "Computing one stock took 24.942864418029785 seconds for stock  47\n",
      "Computing one stock took 23.62320375442505 seconds for stock  48\n",
      "Computing one stock took 28.464062213897705 seconds for stock  50\n",
      "Computing one stock took 24.471997261047363 seconds for stock  51\n",
      "Computing one stock took 24.677863121032715 seconds for stock  52\n",
      "Computing one stock took 24.56072735786438 seconds for stock  53\n",
      "Computing one stock took 23.742053747177124 seconds for stock  55\n",
      "Computing one stock took 24.62784481048584 seconds for stock  56\n",
      "Computing one stock took 23.832945346832275 seconds for stock  58\n",
      "Computing one stock took 24.07708168029785 seconds for stock  59\n",
      "Computing one stock took 23.136264324188232 seconds for stock  60\n",
      "Computing one stock took 25.022351026535034 seconds for stock  61\n",
      "Computing one stock took 24.24364185333252 seconds for stock  62\n",
      "Computing one stock took 25.102110147476196 seconds for stock  63\n",
      "Computing one stock took 25.222439527511597 seconds for stock  64\n",
      "Computing one stock took 24.223545789718628 seconds for stock  66\n",
      "Computing one stock took 24.59578800201416 seconds for stock  67\n",
      "Computing one stock took 24.681321620941162 seconds for stock  68\n",
      "Computing one stock took 25.796226024627686 seconds for stock  69\n",
      "Computing one stock took 24.332093954086304 seconds for stock  70\n",
      "Computing one stock took 24.098965406417847 seconds for stock  72\n",
      "Computing one stock took 24.37999677658081 seconds for stock  73\n",
      "Computing one stock took 24.36702013015747 seconds for stock  74\n",
      "Computing one stock took 23.774020671844482 seconds for stock  75\n",
      "Computing one stock took 25.445552587509155 seconds for stock  76\n",
      "Computing one stock took 25.611732482910156 seconds for stock  77\n",
      "Computing one stock took 25.796969652175903 seconds for stock  78\n",
      "Computing one stock took 25.23886728286743 seconds for stock  80\n",
      "Computing one stock took 24.23678731918335 seconds for stock  81\n",
      "Computing one stock took 23.858065128326416 seconds for stock  82\n",
      "Computing one stock took 24.477622509002686 seconds for stock  83\n",
      "Computing one stock took 25.080896377563477 seconds for stock  84\n",
      "Computing one stock took 24.402374505996704 seconds for stock  85\n",
      "Computing one stock took 25.708073616027832 seconds for stock  86\n",
      "Computing one stock took 24.9608952999115 seconds for stock  87\n",
      "Computing one stock took 23.97846508026123 seconds for stock  88\n",
      "Computing one stock took 24.920360326766968 seconds for stock  89\n",
      "Computing one stock took 24.58743906021118 seconds for stock  90\n",
      "Computing one stock took 25.44894576072693 seconds for stock  93\n",
      "Computing one stock took 24.53475546836853 seconds for stock  94\n",
      "Computing one stock took 25.15030264854431 seconds for stock  95\n",
      "Computing one stock took 25.187326431274414 seconds for stock  96\n",
      "Computing one stock took 24.559832096099854 seconds for stock  97\n",
      "Computing one stock took 24.178826332092285 seconds for stock  98\n",
      "Computing one stock took 25.50965905189514 seconds for stock  99\n",
      "Computing one stock took 24.935321807861328 seconds for stock  100\n",
      "Computing one stock took 22.561012268066406 seconds for stock  101\n",
      "Computing one stock took 20.898823976516724 seconds for stock  102\n",
      "Computing one stock took 20.50692319869995 seconds for stock  103\n",
      "Computing one stock took 21.095335483551025 seconds for stock  104\n",
      "Computing one stock took 22.011160850524902 seconds for stock  105\n",
      "Computing one stock took 23.476886749267578 seconds for stock  107\n",
      "Computing one stock took 22.002018213272095 seconds for stock  108\n",
      "Computing one stock took 20.495619773864746 seconds for stock  109\n",
      "Computing one stock took 19.2833149433136 seconds for stock  110\n",
      "Computing one stock took 20.07324767112732 seconds for stock  111\n",
      "Computing one stock took 20.586605072021484 seconds for stock  112\n",
      "Computing one stock took 19.32565426826477 seconds for stock  113\n",
      "Computing one stock took 18.860809803009033 seconds for stock  114\n",
      "Computing one stock took 18.754929542541504 seconds for stock  115\n",
      "Computing one stock took 18.590317726135254 seconds for stock  116\n",
      "Computing one stock took 19.125389099121094 seconds for stock  118\n",
      "Computing one stock took 19.883260488510132 seconds for stock  119\n",
      "Computing one stock took 19.47242522239685 seconds for stock  120\n",
      "Computing one stock took 19.748105764389038 seconds for stock  122\n",
      "Computing one stock took 21.21643376350403 seconds for stock  123\n",
      "Computing one stock took 19.165088653564453 seconds for stock  124\n",
      "Computing one stock took 18.91553235054016 seconds for stock  125\n",
      "Computing one stock took 18.544361352920532 seconds for stock  126\n",
      "New model catboost perf :  0.28180469876671543\n"
     ]
    }
   ],
   "source": [
    "# Glob book file train (contains all paths for each file in this folder) - Needs this on Kaggle for some reason...\n",
    "df_submission = prediction_function(pred='new_test_laurent',machine=machine,targets=train['target'],all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "df_submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing one stock took 1.3295080661773682 seconds for stock  0\n",
      "Computing one stock took 19.71098566055298 seconds for stock  0\n",
      "Computing one stock took 18.770771026611328 seconds for stock  1\n",
      "Computing one stock took 19.565556526184082 seconds for stock  2\n",
      "Computing one stock took 18.12157964706421 seconds for stock  3\n",
      "Computing one stock took 17.672502040863037 seconds for stock  4\n",
      "Computing one stock took 17.809734582901 seconds for stock  5\n",
      "Computing one stock took 18.797396898269653 seconds for stock  6\n",
      "Computing one stock took 17.796453952789307 seconds for stock  7\n",
      "Computing one stock took 19.23098611831665 seconds for stock  8\n",
      "Computing one stock took 17.82045865058899 seconds for stock  9\n",
      "Computing one stock took 19.89166259765625 seconds for stock  10\n",
      "Computing one stock took 18.97968363761902 seconds for stock  11\n",
      "Computing one stock took 19.61713719367981 seconds for stock  13\n",
      "Computing one stock took 19.993488073349 seconds for stock  14\n",
      "Computing one stock took 18.220035791397095 seconds for stock  15\n",
      "Computing one stock took 20.768505334854126 seconds for stock  16\n",
      "Computing one stock took 20.130249500274658 seconds for stock  17\n",
      "Computing one stock took 17.56786060333252 seconds for stock  18\n",
      "Computing one stock took 17.880221605300903 seconds for stock  19\n",
      "Computing one stock took 18.361985206604004 seconds for stock  20\n",
      "Computing one stock took 18.386884212493896 seconds for stock  21\n",
      "Computing one stock took 17.864022970199585 seconds for stock  22\n",
      "Computing one stock took 18.053248167037964 seconds for stock  23\n",
      "Computing one stock took 18.354435443878174 seconds for stock  26\n",
      "Computing one stock took 17.386546850204468 seconds for stock  27\n",
      "Computing one stock took 18.525962829589844 seconds for stock  28\n",
      "Computing one stock took 19.028507471084595 seconds for stock  29\n",
      "Computing one stock took 17.9544677734375 seconds for stock  30\n",
      "Computing one stock took 18.25822353363037 seconds for stock  31\n",
      "Computing one stock took 19.11836838722229 seconds for stock  32\n",
      "Computing one stock took 17.929858922958374 seconds for stock  33\n",
      "Computing one stock took 19.180862426757812 seconds for stock  34\n",
      "Computing one stock took 18.819993257522583 seconds for stock  35\n",
      "Computing one stock took 18.403592109680176 seconds for stock  36\n",
      "Computing one stock took 17.329546451568604 seconds for stock  37\n",
      "Computing one stock took 19.37334942817688 seconds for stock  38\n",
      "Computing one stock took 18.23464322090149 seconds for stock  39\n",
      "Computing one stock took 17.62850522994995 seconds for stock  40\n",
      "Computing one stock took 18.556363821029663 seconds for stock  41\n",
      "Computing one stock took 17.948184967041016 seconds for stock  42\n",
      "Computing one stock took 19.52715253829956 seconds for stock  43\n",
      "Computing one stock took 18.67521357536316 seconds for stock  44\n",
      "Computing one stock took 18.359708309173584 seconds for stock  46\n",
      "Computing one stock took 19.05351710319519 seconds for stock  47\n",
      "Computing one stock took 17.83107352256775 seconds for stock  48\n",
      "Computing one stock took 21.003684759140015 seconds for stock  50\n",
      "Computing one stock took 18.550883531570435 seconds for stock  51\n",
      "Computing one stock took 18.408048391342163 seconds for stock  52\n",
      "Computing one stock took 18.144099473953247 seconds for stock  53\n",
      "Computing one stock took 17.468026399612427 seconds for stock  55\n",
      "Computing one stock took 19.307689428329468 seconds for stock  56\n",
      "Computing one stock took 17.481480598449707 seconds for stock  58\n",
      "Computing one stock took 17.89911675453186 seconds for stock  59\n",
      "Computing one stock took 18.339269638061523 seconds for stock  60\n",
      "Computing one stock took 18.451306581497192 seconds for stock  61\n",
      "Computing one stock took 17.847277879714966 seconds for stock  62\n",
      "Computing one stock took 18.877721309661865 seconds for stock  63\n",
      "Computing one stock took 18.4993097782135 seconds for stock  64\n",
      "Computing one stock took 18.61386513710022 seconds for stock  66\n",
      "Computing one stock took 18.498258590698242 seconds for stock  67\n",
      "Computing one stock took 18.748605728149414 seconds for stock  68\n",
      "Computing one stock took 18.639591217041016 seconds for stock  69\n",
      "Computing one stock took 17.900473833084106 seconds for stock  70\n",
      "Computing one stock took 18.057511568069458 seconds for stock  72\n",
      "Computing one stock took 18.30683445930481 seconds for stock  73\n",
      "Computing one stock took 18.130788564682007 seconds for stock  74\n",
      "Computing one stock took 17.40302562713623 seconds for stock  75\n",
      "Computing one stock took 18.663095712661743 seconds for stock  76\n",
      "Computing one stock took 18.841461658477783 seconds for stock  77\n",
      "Computing one stock took 19.71643900871277 seconds for stock  78\n",
      "Computing one stock took 18.458293914794922 seconds for stock  80\n",
      "Computing one stock took 18.202548265457153 seconds for stock  81\n",
      "Computing one stock took 18.355590343475342 seconds for stock  82\n",
      "Computing one stock took 17.523953437805176 seconds for stock  83\n",
      "Computing one stock took 18.380852222442627 seconds for stock  84\n",
      "Computing one stock took 20.00572657585144 seconds for stock  85\n",
      "Computing one stock took 18.401553630828857 seconds for stock  86\n",
      "Computing one stock took 19.61076259613037 seconds for stock  87\n",
      "Computing one stock took 18.341952800750732 seconds for stock  88\n",
      "Computing one stock took 18.595271587371826 seconds for stock  89\n",
      "Computing one stock took 18.58327555656433 seconds for stock  90\n",
      "Computing one stock took 19.02808451652527 seconds for stock  93\n",
      "Computing one stock took 18.817668914794922 seconds for stock  94\n",
      "Computing one stock took 19.507562398910522 seconds for stock  95\n",
      "Computing one stock took 18.29094648361206 seconds for stock  96\n",
      "Computing one stock took 17.470298767089844 seconds for stock  97\n",
      "Computing one stock took 17.32562232017517 seconds for stock  98\n",
      "Computing one stock took 18.578351736068726 seconds for stock  99\n",
      "Computing one stock took 18.18234872817993 seconds for stock  100\n",
      "Computing one stock took 18.143513917922974 seconds for stock  101\n",
      "Computing one stock took 17.69465136528015 seconds for stock  102\n",
      "Computing one stock took 17.961124420166016 seconds for stock  103\n",
      "Computing one stock took 18.04081130027771 seconds for stock  104\n",
      "Computing one stock took 17.94726324081421 seconds for stock  105\n",
      "Computing one stock took 17.95006775856018 seconds for stock  107\n",
      "Computing one stock took 19.13332509994507 seconds for stock  108\n",
      "Computing one stock took 18.121541023254395 seconds for stock  109\n",
      "Computing one stock took 17.984930753707886 seconds for stock  110\n",
      "Computing one stock took 18.625244855880737 seconds for stock  111\n",
      "Computing one stock took 17.311659574508667 seconds for stock  112\n",
      "Computing one stock took 18.550395250320435 seconds for stock  113\n",
      "Computing one stock took 18.459067821502686 seconds for stock  114\n",
      "Computing one stock took 18.050346612930298 seconds for stock  115\n",
      "Computing one stock took 17.688732147216797 seconds for stock  116\n",
      "Computing one stock took 19.266754150390625 seconds for stock  118\n",
      "Computing one stock took 20.77840566635132 seconds for stock  119\n",
      "Computing one stock took 21.12949800491333 seconds for stock  120\n",
      "Computing one stock took 20.074288368225098 seconds for stock  122\n",
      "Computing one stock took 20.536083936691284 seconds for stock  123\n",
      "Computing one stock took 21.087611198425293 seconds for stock  124\n",
      "Computing one stock took 20.533121585845947 seconds for stock  125\n",
      "Computing one stock took 19.384165048599243 seconds for stock  126\n",
      "New model catboost perf :  0.28065500102886315\n"
     ]
    }
   ],
   "source": [
    "# Glob book file train (contains all paths for each file in this folder) - Needs this on Kaggle for some reason...\n",
    "df_submission = prediction_function(pred='new_test_laurent_withoutEncoding',machine=machine,targets=train['target'],all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "df_submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.004291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id    target\n",
       "0         0-4  0.004291\n",
       "1         NaN  0.001696\n",
       "2         NaN  0.002704\n",
       "3         NaN  0.002781\n",
       "4         NaN  0.002144\n",
       "...       ...       ...\n",
       "428927    NaN  0.003828\n",
       "428928    NaN  0.003971\n",
       "428929    NaN  0.003561\n",
       "428930    NaN  0.003463\n",
       "428931    NaN  0.002187\n",
       "\n",
       "[428932 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New sub\n",
    "df_submission = prediction_function(pred='new_test_laurent_withoutEncoding_wTrades',machine=machine,targets=train['target'],all_stocks_ids=all_stocks_ids, datapath=datapath)\n",
    "df_submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
